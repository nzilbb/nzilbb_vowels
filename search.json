[{"path":"https://nzilbb.github.io/nzilbb_vowels/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 nzilbb.vowels authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Model-to-PCA workflow","text":"primary purpose package aid ‘model--PCA’ pipeline used series projects NZILBB (Brand et al. 2021; Hurring et al. Forthcoming; Wilson Black, Brand, et al. 2023; Wilson Black, Hay, et al. 2023). article briefly sets pipeline shows use functions package. part workshop delivered part workshop Voices Regional Australia project. ’ll look quick introduction PCA, applying workflow data UC QuakeBox project. material slightly expands Wilson Black, Brand, et al. (2023). almost purposes, better cite article page.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"why-care-about-co-variation","dir":"Articles","previous_headings":"1 Overview","what":"Why care about co-variation?","title":"Model-to-PCA workflow","text":"reasons: Traditionally, sociolinguistic studies focused analyzing individual sounds separately, even considering multiple sounds, except specific cases like vowel shifts (e.g, Gordon 2013; Hay et al. 2015) expected relationship variables structural reasons. , work third-wave sociolinguistics suggests sounds may function interconnected systems e.g. stylistic variation involves combining collections variants convey social meaning (Becker 2014; Podesva 2007). tricky investigate empirically work paradigm explored correlations two variables. recently, ’ve seen shift towards thinking clusters co-varying variables using methods like Principal Component Analysis (PCA) (Brand et al. 2021).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"packages","dir":"Articles","previous_headings":"1 Overview","what":"Packages","title":"Model-to-PCA workflow","text":"use following R packages. Comments provided code block indicate function workflow. Note special package use apply PCA. use function prcomp(), built R.","code":"library(tidyverse) # We use functions from most of the 'tidyverse' # packages so we tend to load them all at once with library(tidyverse). # The best introduction to tidyverse style is \"R for Data Science\": # https://r4ds.hadley.nz/  # ggrepel provides a version of `geom_label` which # automatically repels labels away from other plot # items. library(ggrepel) # We use ggcorrplot to generate correlation plots before applying pca. library(ggcorrplot)  library(mgcv) # mgcv is required to fit GAMMs. library(itsadug) # itsadug is used to extract predictions and random effects # from GAMMs library(broom) # we use `broom` from the `tidymodels` collection to generate # dataframes with summary information from our models.  # `this package`nzilbb.vowels` (not yet released on CRAN) contains functions to # perform Lobanov 2.0 normalisation and apply and visualise PCA. Install it from # github, with, e.g. remotes::install_github('JoshuaWilsonBlack/nzilbb_vowels'). # This may require you to install the 'remotes' package. library(nzilbb.vowels)  # The following line sets the theme for all plots made using the `ggplot2` # package (part of the tidyverse). theme_set(theme_bw())"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"what-is-pca","dir":"Articles","previous_headings":"","what":"What is PCA?","title":"Model-to-PCA workflow","text":"section shortened version Wilson Black, Brand, et al. (2023). details, see paper. especially encourage look supplementary material available . Principal Component Analysis (PCA) technique used simplify complex data sets contain many variables. allows us replace many variables much smaller number Principal Components (PCs) capture majority information contained original dataset convenient way. Usually, lot variables dataset, correlations variables. Sometimes real underlying structure process generated data. instance, look lots body measurements different people, tall people tend longer arms longer legs short people. lead correlation leg measurements arm measurements. resulting pattern two variables might captured single PC tracks overall height. Many variables, one underlying pattern. explain PCA fully, sociophonetic data, let’s consider data 100 speakers using first formant readings three vowel sounds: ‘trap,’ ‘dress,’ ‘kit.’ Changes pronunciation vowels time linked using example, can see PCA finds patterns can link back understanding data. going see PCA can reduce three variables two variables. Three variables lot variables. advantage looking three variables can visualise entire process. following code generates data set need taking data ONZE, comes via nzilbb.vowels package. data look like stage process? anonymous speaker identifier, year birth variable, gender, numerical variable dress, kit, trap. Let’s visualise vowel readings scatter plot, using colour one dimensions. Figure 2.1: Mean first formant values three NZE monophthongs. Figure 2.1, obvious thing note dress kit strongly correlated one another. second observation overall colour points bottom left seems darker top right. suggests kit’s first formant values also correlated values trap kit. observation surprising. Formant frequencies associated vocal track length. interested seeing PCA can capture obvious association , see, can also show linguistically interesting pattern data. code block applies PCA extracts important information initial explanation. explain actually apply PCA detail later. PCA starts finding ‘centre’ data. just point mean value variable. can useful think data ‘cloud’ points. Figure 2.1 depict cloud using spatial position colour. Figure 2.2: DRESS, TRAP, KIT F1 centre point cloud indicated. Figure 2.2 large ‘X’ indicating centre point, mean value, variable. obviously middle \\(x\\) \\(y\\) axes. look shade blue, help colour scale, ’ll see mean value kit somewhere around \\(500%\\). now draw line passing centre ‘maximises variance’. line stays cloud longest. first principal component (PC). look like small example? Figure 2.3: PC1 top centre points. Figure 2.3 shows line. clear passes dress trap ‘longest’ way. harder see kit, spend moments convincing true. expected, given said vocal tract length, PC corresponds overall difference size. one end line, see low values dress, kit, trap; end, see high values variables. drawing first PC, draw second. second PC also passes centre maximises variance, also right angles first PC. visualise now (removing centre point, make plot little readable). Figure 2.4: PC1 PC2. slightly thinner line Figure 2.4 represents PC2. look end line bottom left, see high values kit, lower values dress trap. end see lower values kit, higher values dress trap. PC mean? Speakers one end PC2 lower (vowel space) realisations kit higher realisations dress trap. , innovative respect New Zealand English short front vowel shift. PC2 picking linguistically interesting pattern. third PC drawn point, practice never go many PCs original variables. Often, PCA used produce visualisations complex datasets two dimensions. done, use PC1 PC2 axes plot, plot point respect PC scores. Scores values given speaker PC. speaker completely average production, PC scores \\(0\\) PC. look like current example? Figure 2.5: Plot PC1 PC2 scores speaker. ’s one issue consider. know PC1 captures overall increase decrease formant values, high PC1 score mean formant values increase decrease? drew PC1 PC2 lines, didn’t decide direction. instance, Figure 2.4, haven’t decided whether PC1 scores increase move centre point left plot along PC1 line whether decrease. Either option fine ever PCA function use R make choice . One useful way connect interpretation PCs plot scores make ‘biplot’. ’s ‘bi’ sense plots speakers original variables. looks like case: Figure 2.6: Plot PC1 PC2 scores loadings variable. Figure 2.6 shows loadings original variable PC1 PC2. important keep terminology scores loadings clear mind. Loadings relate original variables PCs, scores relate individual data points, case speakers, PCs. read Figure 2.6? arrows show way original variables move move around plot. go direction arrow, variable increasing value. , instance, start centre move right, along PC1, values original variables increase. , negative PC1 score means across board decrease formant values. case PC2, go centre, kit increases value, dress trap decrease value. , higher PC2 scores correspond innovative position NZE short front vowel shift.1 Figure 2.6 achieved representation speakers terms two variables clear linguistic meaning: overall vocal tract length position NZE short front vowel shift. started, Figure 2.1, three variables, contained formant values. great advantage PCA can often achieve much complex data sets. One final point worth highlighting: interpretation often helped adding additional variables plot. case, yob variable. Presumably, interpretation PC2 right, ’d expect speakers born earlier conservative side PC2 (.e., lower PC2 score). Let’s see ’s right: Figure 2.7: Plot PC1 PC2 scores loadings variable. Colour indicates year birth. Figure 2.7 exactly expect. Low PC2 values correspond speakers born earlier. older speakers conservative. questions raised plot (cloud points taper towards bottom left, instance?), leave reflection.","code":"# `onze_vowels` comes from the `nzilbb_vowels` package. onze_sub <- onze_vowels |>   filter(     vowel %in% c(\"DRESS\", \"KIT\", \"TRAP\")   ) |>   select(     speaker, vowel, F1_50, yob, gender   ) |>   # We take means of the first formant data and keep track of each speaker's   # year of birth and gender.   group_by(     speaker, vowel   ) |>   summarise(     F1_50 = mean(F1_50),     yob = first(yob),     gender = first(gender)   ) |>   ungroup()  # We pivot the dataframe 'wider' so it has a column for each of our three # vowel types. onze_wide <- onze_sub |>   pivot_wider(     names_from = vowel,     values_from = F1_50   ) onze_wide |>   slice_head(n=10) #> # A tibble: 10 × 6 #>    speaker    yob gender DRESS   KIT  TRAP #>    <fct>    <int> <fct>  <dbl> <dbl> <dbl> #>  1 CC_f_020  1936 F       623.  647.  638. #>  2 CC_f_084  1959 F       551.  622.  669. #>  3 CC_f_170  1975 F       535.  589.  630. #>  4 CC_f_186  1956 F       456.  525.  579. #>  5 CC_f_210  1973 F       516.  568.  624. #>  6 CC_f_215  1950 F       558.  635.  658. #>  7 CC_f_245  1977 F       605.  664.  662. #>  8 CC_f_258  1974 F       418.  496.  486. #>  9 CC_f_285  1974 F       472.  450.  532. #> 10 CC_f_429  1947 F       508.  632.  668. initial_plot <- onze_wide |>   ggplot(     aes(       x = DRESS,       y = TRAP,       colour = KIT     )   ) +   geom_point() +   labs(     x = \"DRESS (Hz)\",     y = \"TRAP (Hz)\",     colour = \"KIT (Hz)\"   )  initial_plot onze_pca <- prcomp(   # Select the numeric columns of the data   x = onze_wide |> select(DRESS, KIT, TRAP),   scale = FALSE # NB: this should usually be TRUE. )  onze_wide <- onze_wide |>   mutate(     PC1 = onze_pca$x[, 1],     PC2 = onze_pca$x[, 2]   )  # Extract centre of the point cloud. pca_centre <- onze_pca$center  centre_data <- tibble(   \"DRESS\" = pca_centre[[\"DRESS\"]],   \"KIT\" = pca_centre[[\"KIT\"]],   \"TRAP\" = pca_centre[[\"TRAP\"]] )  # Extract loadings. pca_loadings <- as_tibble(onze_pca$rotation, rownames = \"vowel\")  # Use the loadings and centre to find where each point sits along PC1 and PC2 # when represented in the original 3D space. onze_wide <- onze_wide |>   mutate(     PC1_DRESS = (PC1 * pca_loadings[[1, \"PC1\"]]) + pca_centre[[\"DRESS\"]],     PC1_KIT = (PC1 * pca_loadings[[2, \"PC1\"]]) + pca_centre[[\"KIT\"]],     PC1_TRAP = (PC1 * pca_loadings[[3, \"PC1\"]]) + pca_centre[[\"TRAP\"]],     PC2_DRESS = (PC2 * pca_loadings[[1, \"PC2\"]]) + pca_centre[[\"DRESS\"]],     PC2_KIT = (PC2 * pca_loadings[[2, \"PC2\"]]) + pca_centre[[\"KIT\"]],     PC2_TRAP = (PC2 * pca_loadings[[3, \"PC2\"]]) + pca_centre[[\"TRAP\"]],   ) centre_plot <- initial_plot +   geom_point(data = centre_data, size = 15, shape = 4, stroke = 3) +   labs(     x = \"DRESS (Hz)\",     y = \"TRAP (Hz)\",     colour = \"KIT (Hz)\"   )  centre_plot # This block does some more behind-the-scenes work. PC1_projections <-  onze_wide |>   select(     speaker, PC1_DRESS, PC1_TRAP, PC1_KIT   ) |>   rename(     DRESS = PC1_DRESS,     TRAP = PC1_TRAP,     KIT = PC1_KIT   )  PC2_projections <-  onze_wide |>   select(     speaker, PC2_DRESS, PC2_TRAP, PC2_KIT   ) |>   rename(     DRESS = PC2_DRESS,     TRAP = PC2_TRAP,     KIT = PC2_KIT   )  pc1_plot <- centre_plot +   geom_line(     aes(       x = DRESS,       y = TRAP,       colour = KIT     ),     linewidth = 2,     data = PC1_projections   )  pc1_plot pc2_plot <- initial_plot +   geom_line(     aes(       x = DRESS,       y = TRAP,       colour = KIT     ),     linewidth = 2,     data = PC1_projections   ) +   geom_line(     aes(       x = DRESS,       y = TRAP,       colour = KIT     ),     linewidth = 1.5,     data = PC2_projections   )  pc2_plot ind_plot <- onze_wide |>   ggplot(     aes(       # WARNING: We scale these values as a rough and ready way to get the       # scores on the same scale as the loadings. The methods we will use in the       # real examples below won't have this problem. The upshot: don't just copy       # the code in this block in a real research project!       x = scale(PC1),       y = scale(PC2)     )   ) +   geom_hline(yintercept = 0, linetype=\"dashed\") +   geom_vline(xintercept = 0, linetype=\"dashed\") +   geom_point() +   coord_fixed() +   labs(     x = \"PC1\",     y = \"PC2\"   )  ind_plot bi_plot <- ind_plot +   geom_segment(     aes(       x = 0,       y = 0,       xend = PC1,       yend = PC2     ),     data = pca_loadings,     colour = \"blue\",     linewidth = 1,     arrow = arrow(length = unit(3, \"mm\"))   ) +   geom_label(     aes(       x = PC1,       y = PC2,       label = vowel     ),     data = pca_loadings,     size = 3,     colour = \"blue\",     nudge_x = -0.35   )  bi_plot biplot_sup <- onze_wide |>   ggplot(     aes(       # WARNING: We scale these values as a rough and ready way to get the       # scores on the same scale as the loadings. The methods we will use in the       # real examples below won't have this problem. The upshot: don't just copy       # the code in this block in a real research project!       x = scale(PC1),       y = scale(PC2),       colour = yob     )   ) +   geom_hline(yintercept = 0, linetype=\"dashed\") +   geom_vline(xintercept = 0, linetype=\"dashed\") +   geom_point() +   geom_segment(     aes(       x = 0,       y = 0,       xend = PC1,       yend = PC2     ),     data = pca_loadings,     colour = \"blue\",     linewidth = 1,     arrow = arrow(length = unit(3, \"mm\"))   ) +   geom_label(     aes(       x = PC1,       y = PC2,       label = vowel     ),     data = pca_loadings,     size = 3,     colour = \"blue\",     nudge_x = -0.35   ) +   scale_colour_continuous(type=\"viridis\", option=\"plasma\") +   coord_fixed() +   labs(     x = \"PC1\",     y = \"PC2\",     colour = \"Year of birth\"   )  biplot_sup"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"quakebox-monophthongs","dir":"Articles","previous_headings":"","what":"Quakebox monophthongs","title":"Model-to-PCA workflow","text":"now move example real research use PCA QuakeBox corpus. section follows footsteps Hurring et al. (Forthcoming). anonymised data, stopwords removed,2 available data directory. opened RStudio project, difficulty running following block.3","code":"QB1 <- read_rds('data/QB1_anon.rds')"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"preprocessing-and-filtering","dir":"Articles","previous_headings":"3 Quakebox monophthongs","what":"Preprocessing and filtering","title":"Model-to-PCA workflow","text":"dataframe just loaded already removed words hesitations, tokens without transcribed words unimportant speaker demographics (household location, occupation, areas lived, etc.). remainder section shows additional steps took preprocess filter data. may preferences!","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"tidying","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.1 Preprocessing and filtering","what":"Tidying","title":"Model-to-PCA workflow","text":"First , let’s change DISC notation vowels Wells Lexical Set labels (just find easier understand examining outputs): Next, generate vowel duration column use filtering later. modify Ethnicity column get binary distinction Māori non-Māori. code messy, capturing quite different cases. also change gender codes lower case upper case (e.g. ‘m’ -> ‘M’) compatibility earlier projects. Finally, change character vectors factors. reason necessary mgcv package, use fit GAMMs.","code":"QB1 <- QB1 |>     mutate(       Vowel = fct_recode(         factor(VowelDISC),         FLEECE = \"i\",         KIT = \"I\",         DRESS = \"E\",         TRAP = \"{\",         START = \"#\",         LOT = \"Q\",         THOUGHT = \"$\",         NURSE = \"3\",         STRUT = \"V\",         FOOT = \"U\",         GOOSE = \"u\"     )   ) QB1 <- QB1 |>   mutate(     VowelEnd = as.numeric(VowelEnd),     VowelStart = as.numeric(VowelStart),     VowelDur = VowelEnd - VowelStart   ) QB1$Ethnicity[QB1$Ethnicity == \"NZ mixed ethnicity\"] <- \"Maori\" QB1$Ethnicity[QB1$Ethnicity == \"NZ Maori\"] <- \"Maori\" QB1$Ethnicity[QB1$Ethnicity == \"na\"] <- \"Non-Maori\" QB1$Ethnicity[QB1$Ethnicity == \"Other\"] <- \"Non-Maori\" QB1$Ethnicity[QB1$Ethnicity == \"NZ European\"] <- \"Non-Maori\"   # For convenience, we also change gender coding from 'f', 'm' -> 'F', 'M'. QB1 <- QB1 |>   mutate(     Gender = str_to_upper(Gender)   ) # and we make sure that factor variables are coded as factors (rather than character vectors). factor_vars <- c(   \"Gender\", \"Ethnicity\", \"stress\" )  QB1 <- QB1 |>   mutate(     across(all_of(factor_vars), as.factor),     Age = as.ordered(Age)   )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"filtering","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.1 Preprocessing and filtering","what":"Filtering","title":"Model-to-PCA workflow","text":"now remove tokens , likely , errors introduced forced alignment formant tracking. First, remove tokens: infeasibly short long duration, first formant values 1100 Hz greater, missing speaker metadata, missing formant values. remove unstressed tokens precede liquids. remove tokens formant values 2.5 sd speaker’s mean. code defines function apply standard deviation filter. perhaps slightly complication usual R workflow linguistics, leave can see consequence () changing cut value. order match Brand et al. (2021), remove foot. final filtering step, following Brand et al. (2021), remove speakers fewer 5 tokens remaining vowels. treat minimum getting sensible random intercepts speaker. make judgement? looking health models fit (including distribution random intercepts).","code":"QB1 <- QB1 |>   filter(     between(VowelDur, 0.01, 2), #filter tokens with very short or long vowel     # durations (we take values between 0.01 and 2 seconds)     F1_50 < 1100, # Remove all tokens with F1 at or above 1100hz.     !is.na(Gender), #filter speakers with missing gender     !Gender == \"\",     !is.na(Age), # Filter speakers with missing age.     Age != 'na', # Filter speakers with missing age.     !is.na(F1_50), # Filter missing formant values.     !is.na(F2_50)   ) QB1 <- QB1 |>   filter(     stress != \"0\"   ) |>   mutate(     following_segment_category = fct_collapse(       as_factor(following_segment),       labial = c('m', 'p', 'b', 'f', 'w'),       velar = c('k', 'g', 'N'),       liquid = c('r', 'l'),       other_level = \"other\"     )   ) |>   filter(     !following_segment_category == 'liquid'   ) sd_filter <- function(in_data, sd_limit = 2.5) {   vowels_all_summary <- in_data |>     # Remove tokens at +/- sd limit (default 2.5 sd)     group_by(Speaker, Vowel) |>     summarise(       #calculate the summary statistics required for the outlier removal.       n = n(),       mean_F1 = mean(F1_50, na.rm = TRUE),       mean_F2 = mean(F2_50, na.rm = TRUE),       sd_F1 = sd(F1_50, na.rm = TRUE),       sd_F2 = sd(F2_50, na.rm = TRUE),       # Calculate cut off values.       max_F1 = mean(F1_50) + sd_limit*(sd(F1_50)),       min_F1 = mean(F1_50) - sd_limit*(sd(F1_50)),       max_F2 = mean(F2_50) + sd_limit*(sd(F2_50)),       min_F2 = mean(F2_50) - sd_limit*(sd(F2_50)),       .groups = \"drop_last\"     )    #this is the main outlier filtering step.   out_data <- in_data |>     inner_join(vowels_all_summary, by=join_by(Speaker, Vowel)) |>     mutate(       outlier = ifelse(         F1_50 > min_F1 &           F1_50 < max_F1 &           F2_50 > min_F2 &           F2_50 < max_F2,         FALSE,         TRUE       )     ) |>     group_by(Speaker, Vowel) |>     filter(outlier == FALSE) |>     ungroup() |>     select(       -c(         outlier, n, mean_F1, mean_F2, sd_F1,         sd_F2, max_F1, min_F1, max_F2, min_F2,       )     ) }  QB1 <- QB1  |>   sd_filter(sd_limit = 2.5) QB1 <- QB1 |>   filter(     Vowel != \"FOOT\"   ) |>   mutate(     # Remove FOOT from the factor levels.     Vowel = droplevels(Vowel)   ) low_speakers <- QB1 |>   # .drop is required to capture situations in which a speaker has NO tokens for   # a given vowel. It ensures a group for all levels of the vowel factor   # (including those not present in the data for a given speaker)   group_by(Speaker, Vowel, .drop = FALSE) |>   count() |>   ungroup() |>   filter(n < 5) |>   pull(Speaker)  QB1 <- QB1 |>   ungroup() |>   filter(!Speaker %in% low_speakers)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"normalisation","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.1 Preprocessing and filtering","what":"Normalisation","title":"Model-to-PCA workflow","text":"normalise vowels using Lobanov 2.0 method. Lobanov normalisation mean means approach handle different token counts across vowel categories.4 Lobanov 2.0 implemented lobanov_2() function nzilbb.vowels package.","code":"# The Lobanov 2.0 function requires that the data be ordered with Speaker id, # vowel name, F1 (Hz) and F2 (Hz) as the first four columns.  QB1 <- QB1 |>   # Reorder the data into the column order required by the Lobanov 2 function.   relocate(Speaker, Vowel, F1_50, F2_50) |>   lobanov_2()"},{"path":[]},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"why","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.2 GAMM models","what":"Why?","title":"Model-to-PCA workflow","text":"pipeline present can called ‘model PCA’ pipeline. applying PCA values extracted models. specific, apply PCA random intercepts extracted GAMM models. random intercepts represent measure far speakers production vowel varies expect given information built model. ? Consider PC1 toy example PCA . Sociophoneticians typically interested fact speakers longer vocal tracts produce lower frequency formants. feature voice don’t take socially meaningful. get rid kind variation means normalisation. different projects, different kinds variation might want ignore. know, instance, older speakers distinct production younger speakers. , , within age group, speakers innovative production others. get PCA, need control age speakers. including measure age models. Gia Hurring’s PhD thesis (progress) includes exploration consequences modelling decisions exploring covariation vowels consonants, look .","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"fit","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.2 GAMM models","what":"Fit","title":"Model-to-PCA workflow","text":"place provide explanation GAMM modelling. Readers directed Sóskuthy (2017). fit distinct GAMM model vowel formant pair .e., separate models dress F1, dress F2 etc. models predict Lobanov 2.0 normalised formant values parametric term gender four-knot smooth age category levels gender (‘M’ ‘F’). also fit articulation rate control variable random effect intercepts speaker word. pattern code block , nesting data, fitting models, extracting intercepts, set detail Wilson Black (2022). begin, ’ll need numeric representation age categories convert speaker, gender, word factor variables. count many speakers category check whether age categories excluded: ’ve got 85+ speakers, remove 85+ category run GAMMs. code block , can take quite long time run. set run unless specifically requested (.e., pressing green ‘run’ button RStudio). models large. may run memory. main reason models large random intercept word. remove low frequency words model likely fit. good idea actual research project, help follow workshop! stage process, check models good. falls general heading GAMM modelling. thing might find difficult models vowel stored dataframe. , access model dress F1, use, e.g.: won’t dwell , falls general heading learning fit GAMMs. interested, look kind model tests apply , , .","code":"# Check that age values in the correct order. levels(QB1$Age) #> [1] \"18-25\" \"26-35\" \"36-45\" \"46-55\" \"56-65\" \"66-75\" \"76-85\" \"85+\"   \"na\" # Correct!  # Convert to integer and do to factor conversions for speaker and word. QB1 <- QB1 |>   mutate(     age_category_numeric = as.integer(Age),     Speaker = as.factor(Speaker),     Gender = as.factor(Gender),     Word = as.factor(Word)   ) QB1 |>   group_by(Age) |>   summarise(     speaker_count = n_distinct(Speaker)   ) #> # A tibble: 8 × 2 #>   Age   speaker_count #>   <ord>         <int> #> 1 18-25            43 #> 2 26-35            19 #> 3 36-45            50 #> 4 46-55            71 #> 5 56-65            63 #> 6 66-75            36 #> 7 76-85            11 #> 8 85+               4 QB1_models <- QB1 |>   filter(     Age != \"85+\"   ) |>   select(     -F1_50, -F2_50   ) |>   pivot_longer(     cols = F1_lob2:F2_lob2,     names_to = \"formant_type\",     values_to = \"formant_value\"   ) |>   group_by(Vowel, formant_type) |>   nest() |>   mutate(     model = map(       data,       ~ bam(           #main effects           formant_value ~ Gender +             s(age_category_numeric, k = 4, by = Gender) +             # control vars             s(articulation_rate, k = 3) +             # random effects             s(Speaker, bs='re') + s(Word, bs='re'),           discrete = TRUE,           nthreads = 4,           data = .x       )     )   )  # save the models to an external file. write_rds(QB1_models, here('models', 'QB1models.rds')) dress_f1_model <- QB1_models |>   filter(     Vowel == \"DRESS\",     formant_type == \"F1_lob2\"   ) |>   pull(model) |>   pluck(1)  # or, in a more 'base R' style: dress_f1_model <- QB1_models[   QB1_models$Vowel == \"DRESS\" & QB1_models$formant_type == \"F1_lob2\", ]$model[[1]]"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"plot","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.2 GAMM models","what":"Plot","title":"Model-to-PCA workflow","text":"’re skipping details modelling process, absolutely essential look plots predictions model. extract predictions vowel model age categories male female speakers. ignore question significance. want see looks like include statistically significant change time, see . First, extract predictions model: can plot predictions extracted vowel space. Figure 3.1: Change realisation monopthongs apparent time. patterns caused us little bit head scratching. Now place go detail. place go detail. , main thing know speaker random intercepts models provide us representations far individual speakers deviate patterns (along variation articulation rate) direction.","code":"to_predict <- list(   \"age_category_numeric\" = seq(from=1, to=7, by=1), # All age categories.   \"Gender\" = c(\"M\", \"F\") )  QB1_preds <- QB1_models |>   mutate(     prediction = map(       model,       ~ get_predictions(model = .x, cond = to_predict, print.summary = FALSE)     )   ) |>   select(     Vowel, formant_type, prediction   ) |>   unnest(prediction) |>   # This step is important. It ensures that, when we plot,   # arrows go from oldest to youngest speakers.   arrange(     desc(age_category_numeric)   )  QB1_preds <- QB1_preds |>   select( # Remove unneeded variables     -articulation_rate,   ) |>   pivot_wider( # Pivot     names_from = formant_type,     values_from = c(fit, CI)   ) |>   rename(     F1_lob2 = fit_F1_lob2,     F2_lob2 = fit_F2_lob2   ) # Tol colours, designed to be colour blind friendly. vowel_colours <- c(   DRESS = \"#777777\", # This is the 'bad data' colour for maps   FLEECE = \"#882E72\",   GOOSE = \"#4EB265\",   KIT = \"#7BAFDE\",   LOT = \"#DC050C\",   TRAP = \"#878100\", # \"#F7F056\",   START = \"#1965B0\",   STRUT = \"#F4A736\",   THOUGHT = \"#72190E\",   NURSE = \"#E8601C\",   FOOT = \"#5289C7\" )  # add labels to data for plotting purposes QB1_preds <- QB1_preds |>     group_by(Vowel, Gender) |>     mutate(       vowel_lab = if_else(         age_category_numeric == max(age_category_numeric),         Vowel,         \"\"       )     ) |>     ungroup()  QB1_preds |>   ggplot(     aes(       x = F2_lob2,       y = F1_lob2,       colour = Vowel,       label = vowel_lab,       group = Vowel     )   ) +   geom_path(     arrow = arrow(         ends = \"last\",         type=\"closed\",         length = unit(2, \"mm\")       ),     linewidth = 1   ) +   geom_point(     data = ~ .x |>       filter(         !vowel_lab == \"\"       ),     show.legend = FALSE,     size = 1.5   ) +   geom_label_repel(     min.segment.length = 0, seed = 42,     show.legend = FALSE,     fontface = \"bold\",     size = 10 / .pt,     label.padding = unit(0.2, \"lines\"),     alpha = 1,     max.overlaps = Inf   ) +   scale_x_reverse(expand = expansion(mult = 0.2), position = \"top\") +   scale_y_reverse(expand = expansion(mult = 0.1), position = \"right\") +   scale_colour_manual(values = vowel_colours) +   facet_grid(       cols = vars(Gender)   ) +   labs(     x = \"F2 (normalised)\",     y = \"F1 (normalised)\"   ) +   theme(     plot.title = element_text(face=\"bold\"),     legend.position=\"none\"   )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"extract-intercepts","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.2 GAMM models","what":"Extract intercepts","title":"Model-to-PCA workflow","text":"following code block extracts random intercepts model using function get_random() itsadug package. use values now stored QB1_intercepts input PCA analysis. switch PCA, let’s remove models memory take lot room.","code":"QB1_intercepts <- QB1_models |>   mutate(     # for each model we get the speaker random intercepts, rather than the     # word random intercepts.     random_intercepts = map(       model,       ~ get_random(.x)$`s(Speaker)` |>         as_tibble(rownames = \"Speaker\") |>         rename(intercept = value)     )   ) |>   select(     Vowel, formant_type, random_intercepts   ) |>   unnest(random_intercepts) |>   arrange(as.character(Vowel)) |>   ungroup()  head(QB1_intercepts) rm(QB1_models)"},{"path":[]},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"applying-pca","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.3 PCA","what":"Applying PCA","title":"Model-to-PCA workflow","text":"options carrying PCA. use base R function prcomp(), supplemented pca_test() function nzilbb.vowels package. functions require matrix numerical variables input. variable column. case, want vowel-formant pair, e.g. dress F1, nurse F2, etc, column. requires us pivot random intercepts form long form wide form. following code block carries . like leave Speaker column dataframe, even though removed time run PCA. helps remain confident values correspond specific speakers.5 ’s worth quick sanity check actually applying PCA. PCA finds patterns covariation data. patterns, pairwise correlations variables. can look visually correlation plot. Figure 3.2: Pairwise correlations extracted random intercepts. pattern various colours, reasonably deep blue red good news point process. test whether number magnitude correlations significantly different see random data. instance, producing following plots using plot_correlation_magnitudes() plot_correlation_counts() functions nzilbb.vowels. Figure 3.3: Correlation tests applied byu-speaker intercepts derived QuakeBox models. () shows distribution correlation magnitudes permuted data (teal), actual data (red). (B) shows counts statistically significant correlations (\\(lpha\\) = 0.05) permuted data (teal) actual data (red). Figure 3.3 shows many high magnitude correlations dataset random data (panel ) count statistically significant pairwise correlations (\\(\\alpha\\) = 0.05) much higher found random data (panel B). Let’s finally apply PCA using prcomp() function. almost always good idea set scale = TRUE. default value FALSE consistency earlier programming language (‘S’). Different vowels, even normalised, different variances. don’t scale, variables variance dominate even don’t appear interesting patterns covariation. qb_pca contain, now? look RStudio viewer. key things note qb_pca$x, contains speaker scores, qb_pca$rotation, contains loadings. also qb_pca$sdev captures much variation PC captures used determine many PCs want use. Let’s look qb_pca$rotation briefly, looking loadings PC1 . Lots patterns visible output. instance, pattern toy example . See dress trap F1 loaded positively, kit F1 negative loading. gives initial indication short front vowel shift captured PC perhaps connected patterns covariation. explored detail Hurring et al. (Forthcoming).","code":"QB1_intercepts <- QB1_intercepts |>   # Create a column to store our eventual column names   mutate(     # Combine the 'vowel' and 'formant_type' columns as a string.     vowel_formant = str_c(Vowel, '_', formant_type),     # Remove '_lob2' for cleaner column names     vowel_formant = str_replace(vowel_formant, '_lob2', '')   ) |>   ungroup() |>   # Remove old 'vowel' and 'formant_type' columns   select(-c(Vowel, formant_type)) |>   # Make data 'wider', by...   pivot_wider(     names_from = vowel_formant, # naming columns using 'vowel_formant'...     values_from = intercept # and values from intercept column   )  # There's some models with missing values for some speakers. We insist on # a value for each variable. QB1_intercepts <- QB1_intercepts |>   filter(complete.cases(QB1_intercepts))  head(QB1_intercepts) #> # A tibble: 6 × 21 #>   Speaker     DRESS_F1 DRESS_F2 FLEECE_F1 FLEECE_F2 GOOSE_F1 GOOSE_F2  KIT_F1 #>   <chr>          <dbl>    <dbl>     <dbl>     <dbl>    <dbl>    <dbl>   <dbl> #> 1 QB_NZ_F_103  -0.0976 -0.00990    0.226    -0.171   0.0213   0.0815   0.209  #> 2 QB_NZ_F_107  -0.142  -0.00706   -0.0904    0.0136  0.0969   0.0987  -0.0130 #> 3 QB_NZ_F_121  -0.0537  0.127      0.0717    0.0198 -0.00300 -0.00983  0.0671 #> 4 QB_NZ_F_131  -0.0241  0.0382     0.112    -0.0563  0.0228  -0.0884   0.395  #> 5 QB_NZ_F_132   0.101  -0.0740    -0.0170    0.147  -0.0490   0.0427  -0.0789 #> 6 QB_NZ_F_133  -0.0111  0.0529    -0.136     0.129   0.0659  -0.0688   0.0668 #> # ℹ 13 more variables: KIT_F2 <dbl>, LOT_F1 <dbl>, LOT_F2 <dbl>, #> #   NURSE_F1 <dbl>, NURSE_F2 <dbl>, START_F1 <dbl>, START_F2 <dbl>, #> #   STRUT_F1 <dbl>, STRUT_F2 <dbl>, THOUGHT_F1 <dbl>, THOUGHT_F2 <dbl>, #> #   TRAP_F1 <dbl>, TRAP_F2 <dbl> QB1_intercepts |>   select(-Speaker) |>   as.matrix() |>   cor() |>   ggcorrplot() +   theme(     axis.text.x = element_text(size = 8),     axis.text.y = element_text(size = 8)   ) cor_test <- correlation_test(   QB1_intercepts |>     select(-Speaker),   n = 100,   cor.method = \"pearson\" )  plot_correlation_magnitudes(cor_test) +   labs(title = NULL) +   plot_correlation_counts(cor_test) +   labs(title = NULL) +   plot_annotation(tag_levels = \"A\") qb_pca <- prcomp(   # We use the intercepts without the speaker column.   QB1_intercepts |> select(-Speaker),   scale = TRUE ) qb_pca$rotation[, \"PC1\"] #>    DRESS_F1    DRESS_F2   FLEECE_F1   FLEECE_F2    GOOSE_F1    GOOSE_F2  #>  0.30189388 -0.20305569 -0.32250732  0.32900513 -0.27718563  0.09453797  #>      KIT_F1      KIT_F2      LOT_F1      LOT_F2    NURSE_F1    NURSE_F2  #> -0.26712816  0.29556390  0.01724038  0.03805744  0.29210571 -0.26058661  #>    START_F1    START_F2    STRUT_F1    STRUT_F2  THOUGHT_F1  THOUGHT_F2  #> -0.11924109 -0.13465252 -0.17660130 -0.06213031  0.12018776  0.09017500  #>     TRAP_F1     TRAP_F2  #>  0.31817510 -0.25436522"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"how-many-pcs","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.3 PCA","what":"How many PCs?","title":"Model-to-PCA workflow","text":"select small number PCs keep. trying reduce dimensionality original data. want fewer variables work . PCA produces many PCs variables original data, , things working well, information data set captured first PCs. determine many PCs keep looking much variance PC explains. useful way think terms percentage variation explained PC. can turn pca$sdev proportion variance explained plot follows:6 Figure 3.4: Screeplot percentage variance explained first ten PCs. Figure 3.4 example “screeplot”. Various methods determining many PCs take . Almost amount rules thumb, deterministic necessarily appropriate. ’s way avoid applying judgement ! One common ways use screeplots decide ‘elbow’ plot. plot cease steep? make argument including PC1 , perhaps PC1 PC2 basis. response adopt permutation bootstrapping approaches sort discussed (Vieira 2012) implemented also PCAtest package (Camargo 2022). gives us way decide much variance expect explained given PC given absence patterns data. approach uses pca_test() function nzilbb.vowels package. apply follows: can plot variant screeplot plot_variance_explained() function. Figure 3.5: Screeplot error bars. Figure 3.5 introduces two changes saw Figure 3.4. First, red bars estimated confidence intervals variance explained. estimated bootstrapping. , repeating analysis excluding different portions data. Second, blue bars indicate distribution data randomly shuffled column. argue PCs red point appears blue bar explicitly mentioned somewhere. However, often PCs close blue bar uninteresting can rejected. usually require sentence two, might appear supplementary materials. ’ll see looks like moment. second thing note scenarios two red bars overlap. happens PC3 PC4 plot . situation two PCs explain amount variance, PC loadings can become unstable. discuss ways deal later workshop.","code":"variance_explained <- as_tibble(   qb_pca$sdev^2 / sum(qb_pca$sdev^2) * 100,   rownames = \"PC\" )  # This bit of code turns the column with PC labels into a factor in the correct # order, otherwise we get PC1, PC10, PC11, ... PC2...; rather than PC1, PC2, # PC3... (i.e. alphabetical order rather than numerical) variance_explained <- variance_explained |>   mutate(     PC = factor(       str_c(\"PC\", PC),       levels = str_c(\"PC\", 1:nrow(variance_explained))     )   )  variance_explained |>   # We'll just take the first 10 PCs.   filter(     PC %in% str_c(\"PC\", 1:10)   ) |>   ggplot(     aes(       x = PC,       y = value     )   ) +   geom_col() +   labs(     y = \"Variance explained (%)\"   ) qb_pca_test <- pca_test(   QB1_intercepts |> select(-Speaker),   n = 100 # The number of permutations to try. I'd go up to 500 for anything   # you publish, but leaving it at a lower number is better when experimenting. ) plot_variance_explained(qb_pca_test, pc_max = 10)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"more-details-about-stability","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.3 PCA > 3.3.2 How many PCs?","what":"More details about ‘stability’","title":"Model-to-PCA workflow","text":"actually two issues ’re dealing thinking red points bars: one PC reliably distinct next PC? true red point PC\\(n\\) falls outside red bars PC\\(n+1\\). confidence intervals put loadings next section stable? true bars PC\\(n\\) overlap bars PC\\(n+1\\).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"interpreting-pcs","dir":"Articles","previous_headings":"3 Quakebox monophthongs > 3.3 PCA","what":"Interpreting PCs","title":"Model-to-PCA workflow","text":"already noted, interpret PCs looking loadings. Just previous section, ’ll look standard way looking PC loadings introduce preferred way (, uses pca_test()). output prcomp(), can use pca_contrib_plot() function nzilbb.vowels. plots used BRANDETAL.7 Figure 3.6: PC1 loadings without 50% cutoff. Figure 3.6 shows loadings PC1 without cutoff value 50%. accept 50% cutoff, interpret variables right hand side red line. number chosen advance. researchers instead use ‘elbow rule’ . case, likely choose variables trap F2 right. , area one right answer. case, ’d argue 50% rule, clear rationale drawing line goose F1 nurse F1. movement , repeat example , kit F1, seems plausibly associated variables right red line. now prefer use plot_loadings() function nzilbb.vowels, adds confidence bars ‘index loadings’. Index loadings loadings multiplied amount variance explained PC. approach encouraged Vieira (2012). penalises loadings weaker PCs, can often represent noise data. Figure 3.7: Index loadings PC1. look Figure 3.7, see black indications loading direction. case, PC1 increases, fleece F2 increases (loading ‘plus’ sign) fleece F1 decreases (loading ‘negative’ sign). index loading appear blue bars, larger expected data structure. clear rule blue bars: ignore variables whose loadings appear blue bars. turn red bars, back realm rules thumb judgement. red bars indicate 95% range index loadings variable bootstrapped samples. treat indicative stable covariation variables . lower limit red bar gets near zero, reason think corresponding variable happens correlated others dataset. using PCA exploratory spirit generate hypotheses, variable red bar starting near zero excluded claimed patterns covariation. area need work explore consequences alternative rules including variables.8 repeat, can unclear: take plots like Figure 3.7 give clear advice variables definitely excluded, definite advice variables included. Figure 3.7 mean? can read relationships loadings. , mentioned , takes mental steps, especially moving loading plots vowel space. started using plot_pc_vs() function quickly plot loadings vowel space. takes mental load . Figure 3.8: PC1 loadings represented vowel space. PC1 scores increase, speakers vowels tend move direction arrows. overall impression Figure 3.8 higher values PC1 lead canonically ‘conservative’ realisations NZE vowels. includes fleece, goose, nurse vowels typically included short front vowel shift. can’t see arrows plot device, change size plot. RStudio, can press ‘show new window’ button appears top right plot output code chunck. Sometimes, easier interpretation direction PC changed. case, might want positive PC values indicate innovative rather conservative speaker. nzilbb.vowels package function pc_flip() purpose. works output prcomp() pca_test(). Let’s flip PC1 two PCA objects currently . Now repeat Figure 3.8, see loadings reversed. Figure 3.9: PC1 loadings represented vowel space. PC1 scores increase, speakers vowels tend move direction arrows. Flipped previous figure. PC2? Figure 3.10: Index loadings PC2. four clearly covarying variables: strut, thought start F2, thought F1. happy see pattern, also appears ONZE corpus (Brand et al. 2021). open us include exclude lot F2. look like vowel space? Figure 3.11: PC2 loadings represented vowel space. (Brand et al. 2021), Figure 3.11 shows pattern back vowels can less linear, thought fronting lot strut back, vice versa. feature PCA excited us close match QB1 PCs PCs derived ONZE. Patterns discernible long time depth ONZE also present much recent data collection.","code":"pca_contrib_plot(qb_pca, pc_no = 1, cutoff = NULL) /   pca_contrib_plot(qb_pca, pc_no = 1, cutoff = 50) plot_loadings(qb_pca_test, pc_no = 1) pc1_vs <- plot_pc_vs(   QB1 |> relocate(Speaker, Vowel, F1_lob2, F2_lob2),   qb_pca_test,   pc_no = 1 ) pc1_vs qb_pca_test <- pc_flip(qb_pca_test, pc_no = 1) qb_pca <- pc_flip(qb_pca, pc_no = 1) pc1_vs <- plot_pc_vs(   # We need the original vocalic data to find the mean values of each vowel.   # The function assumes the data's first four columns are speaker id, vowel id,   # F1, and F2. In this case, we want normalised values, so we use `relocate()`   # to ensure that they are in the third and fourth column (rather than raw   # values).   QB1 |> relocate(Speaker, Vowel, F1_lob2, F2_lob2),   qb_pca_test,   pc_no = 1,   is_sig = TRUE # This option is only available when plotting pca_test() results. ) pc1_vs plot_loadings(qb_pca_test, pc_no = 2) pc2_vs <- plot_pc_vs(   QB1 |> relocate(Speaker, Vowel, F1_lob2, F2_lob2),   qb_pca_test,   pc_no = 2,   is_sig = TRUE ) pc2_vs"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Model-to-PCA-workflow.html","id":"final-words-and-future-directions","dir":"Articles","previous_headings":"","what":"Final words and future directions","title":"Model-to-PCA workflow","text":"explanations PCA within linguistics take different tack presented . instance, Desagulier (2020) presents PCA one amongst number exploratory methods can used draw conclusions ’corpus (438). Exploratory use PCA provide strong test patterns pick . can make predictions PCA show another data set (Hurring et al. (Forthcoming)). can also use bootstrapping methods (pca_test()) help mitigate idiosyncratic features corpus. future work, ’ll look use bootstrapped confidence intervals index loadings compared rotation-based method. work towards presented Methods Dialectology last year (Sheard Wilson Black 2024). also important note existence Functional Principal Component Analysis. Another stream research NZILBB working method recently. One possible way Gubian, Torreira, Boves (2015).","code":""},{"path":[]},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"why-rotate","dir":"Articles","previous_headings":"","what":"Why rotate?","title":"PCA and Rotation","text":"often useful apply rotations outputs PCA. article demonstrates options rotation using functions nzilbb.vowels. First, discuss use rotation comparing PCA applied across distinct data sets. discuss use rotation PCA applied single dataset. NB: page taken work--progress!","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"packages","dir":"Articles","previous_headings":"","what":"Packages","title":"PCA and Rotation","text":"Let’s load packages.","code":"library(nzilbb.vowels) library(tidyverse)  # plotting library(ggrepel) library(gganimate)  # GAMMS library(mgcv) library(itsadug)  # for bootstrapping library(rsample)  theme_set(theme_bw())"},{"path":[]},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"are-the-same-patterns-of-covariation-present-in-two-data-sets","dir":"Articles","previous_headings":"3 Comparing PCA across two data sets","what":"Are the same patterns of covariation present in two data sets?","title":"PCA and Rotation","text":"Hurring et al. (Forthcoming) show similar patterns covariation present data ONZE corpus QuakeBox corpus, two distinct corpora New Zealand English (NZE). order mimic results Hurring et al. (Forthcoming) apply model--PCA pipeline qb_vowels data included nzilbb.vowels. dataset small subset data considered Hurring et al. (Forthcoming) contains 11 speakers 7 age categories, balanced gender. Let’s look predictions models. code borrowed model--PCA vignette. Figure 3.1: Predictions QuakeBox models. trajectories Figure 3.1 line found Hurring et al. (Forthcoming). ’re interested PCA rotation , ’ll skip model criticism go straight extracting random intercepts. Now let’s PCA new intercepts onze intercepts Brand et al. (2021). ’ll look variances explained . Figure 3.2: Variance explained QB PCs. Figure 3.3: Variance explained ONZE PCs. Let’s look first two PCs see ’s similarity patterns emerge. Figure 3.4: Loadings PC1 PC2 across ONZE QB. Spend time peering Figure 3.4. start see patterns common , captured just looking PC1 PC2. Hurring et al. (Forthcoming) focuses similarity two corpora finds means looking loadings . find nice correspondence PC2 ONZE PC1 QB.1 nice argument nothing special done PCs might suggest rigging things favour finding similarities. , instead, ’re interested meaningful differences patterns two corpora. might want maximise similarity two interpreting differences. can achieved rotation. point worth emphasising variance PCA sense large changes PC loadings small changes input data. Variance loadings particularly high cases multiple PCs explain similar amounts variance one another. point confidence intervals around plots variance explained . , Figure 3.3, PC1 PC2 overlapping confidence intervals, expect lot variance variables get loaded PC (combination PCs). kind instability can easily visualised showing PC1 PC2 ONZE data across 15 bootstrapped samples. Figure 3.5: Variation PC1 PC2 loadings (ONZE). moral Figure 3.5 patterns pretty consistent even switch PC1 PC2 polarity switches negative positive. red collection arrows blue collections arrows show ‘leader/lagger’ ‘back vowel configuration’ patterns identified Brand et al. relative positions arrows patterns consistent, captured differently PC1 PC2 space different samples original data. comes comparing ONZE QB, interested pattern captured PC1 one corpus PC2 . might indicate something relative strength patterns community, confidence intervals variance explained PC1 PC2 overlap corpora (.e., Figure 3.3 Figure 3.2 show PCs overlapping confidence intervals).","code":"qb_models <- qb_vowels |>    # normalize   lobanov_2() |>   pivot_longer(     cols = c(\"F1_lob2\", \"F2_lob2\"),     names_to = \"formant_type\",     values_to = \"formant_value\"   ) |>    # changes for compatibility with GAMM modellings.   mutate(     speaker = factor(speaker),     word = factor(word),     gender = factor(participant_gender),     age_numeric = as.numeric(factor(participant_age_category))   ) |>    # We'll remove FOOT   filter(     vowel != \"FOOT\"   ) |>    group_by(vowel, formant_type) |>    nest() |>    mutate(     model = map(       data,       ~ bam(         formant_value ~ gender +            s(age_numeric, by=gender, k = 4) +           s(word_freq, k=4) +           s(articulation_rate, k=4) +           s(word, bs=\"re\") +           s(speaker, bs=\"re\"),         data = .x,         discrete = TRUE,         nthreads = 8       )     )   ) to_predict <- list(   \"age_numeric\" = seq(from=1, to=7, by=1), # All age categories.   \"gender\" = c(\"M\", \"F\") )  qb_preds <- qb_models |>   mutate(     prediction = map(       model,       ~ get_predictions(model = .x, cond = to_predict, print.summary = FALSE)     )   ) |>   select(     vowel, formant_type, prediction   ) |>   unnest(prediction) |>   arrange(     desc(age_numeric)   ) |>    pivot_wider( # Pivot     names_from = formant_type,     values_from = c(fit, CI)   ) |>   rename(     F1_lob2 = fit_F1_lob2,     F2_lob2 = fit_F2_lob2   )  vowel_colours <- c(   DRESS = \"#777777\", # This is the 'bad data' colour for maps   FLEECE = \"#882E72\",   GOOSE = \"#4EB265\",   KIT = \"#7BAFDE\",   LOT = \"#DC050C\",   TRAP = \"#878100\", # \"#F7F056\",   START = \"#1965B0\",   STRUT = \"#F4A736\",   THOUGHT = \"#72190E\",   NURSE = \"#E8601C\",   FOOT = \"#5289C7\" )  # add labels to data for plotting purposes qb_preds <- qb_preds |>     group_by(vowel, gender) |>     mutate(       vowel_lab = if_else(         age_numeric == max(age_numeric),         vowel,         \"\"       )     ) |>     ungroup()  qb_preds |>   ggplot(     aes(       x = F2_lob2,       y = F1_lob2,       colour = vowel,       label = vowel_lab,       group = vowel     )   ) +   geom_path(     arrow = arrow(         ends = \"last\",         type=\"closed\",         length = unit(2, \"mm\")       ),     linewidth = 1   ) +   geom_point(     data = ~ .x |>       filter(         !vowel_lab == \"\"       ),     show.legend = FALSE,     size = 1.5   ) +   geom_label_repel(     min.segment.length = 0, seed = 42,     show.legend = FALSE,     fontface = \"bold\",     size = 10 / .pt,     label.padding = unit(0.2, \"lines\"),     alpha = 1,     max.overlaps = Inf   ) +   scale_x_reverse(expand = expansion(mult = 0.2), position = \"top\") +   scale_y_reverse(expand = expansion(mult = 0.1), position = \"right\") +   scale_colour_manual(values = vowel_colours) +   facet_grid(       cols = vars(gender)   ) +   labs(     x = \"F2 (normalised)\",     y = \"F1 (normalised)\"   ) +   theme(     plot.title = element_text(face=\"bold\"),     legend.position=\"none\"   ) qb_intercepts <- qb_models |>   mutate(     random_intercepts = map(       model,       ~ get_random(.x)$`s(speaker)` |>         as_tibble(rownames = \"speaker\") |>         rename(intercept = value)     )   ) |>   select(     vowel, formant_type, random_intercepts   ) |>   unnest(random_intercepts) |>   arrange(as.character(vowel)) |>   ungroup() |>    mutate(     # Combine the 'vowel' and 'formant_type' columns as a string.     vowel_formant = str_c(vowel, '_', formant_type),     # Remove '_lob2' for cleaner column names     vowel_formant = str_replace(vowel_formant, '_lob2', '')   ) |>   ungroup() |>   # Remove old 'vowel' and 'formant_type' columns   select(-c(vowel, formant_type)) |>   # Make data 'wider', by...   pivot_wider(     names_from = vowel_formant, # naming columns using 'vowel_formant'...     values_from = intercept # and values from intercept column   ) %>%    # take only complete cases (some speakers don't have enough vowels for models)   # NB: a use for the magrittr pipe rather than the native R pipe.   filter(     complete.cases(.)   ) qb_pca_test <- pca_test(   qb_intercepts |> select(-speaker),   n = 100 )  # change variable names to match QB. QB names are of form VOWEL_FORMANT. ONZE # names are of formant FORMANT_VOWEL.  onze_intercepts_full <- onze_intercepts_full |>    rename_with(     ~ paste0(       str_extract(.x, \"_([A-Z]*)\", group=1),       \"_\",       str_extract(.x, \"F[1-2]\")     ),     .cols = matches(\"F[0-9]\")   )  onze_pca_test <- pca_test(   onze_intercepts_full |> select(-speaker),   n = 100 ) plot_variance_explained(qb_pca_test) plot_variance_explained(onze_pca_test) loadings_to_plot <- bind_rows(   \"QB\" = qb_pca_test$loadings,   \"ONZE\" = onze_pca_test$loadings,   .id = \"Corpus\" )  loadings_to_plot |>   pivot_wider(     names_from = \"PC\",     values_from = low_null:sig_loading   ) |>    # annoyingly the variables are of form Fx_VOWEL in ONZE and VOWEL_Fx in QB.   # we change to match QB   ggplot(     aes(       xend = loading_PC1,       yend = loading_PC2,       label = variable     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=loading_PC1, y = loading_PC2), size = 2) +   scale_x_continuous(expand = expansion(mult=0.1)) +   facet_grid(cols = vars(Corpus)) set.seed(7)  data_boots <- bootstraps(onze_intercepts_full |> select(-speaker), times = 15)  onze_bootstrapped <- tibble(   iteration = 1:15,   pca = map(     data_boots$splits,     ~ prcomp(       as_tibble(.x),       scale = TRUE     )   ) )  onze_bootstrapped <- onze_bootstrapped |>    mutate(     PC1_loadings = map(        pca, ~ .x$rotation[, 1]     ),     PC2_loadings = map(       pca, ~ .x$rotation[, 2]     ),     variable = map(       pca, ~ rownames(.x$rotation)     )   )  onze_loadings <- onze_bootstrapped |>    # ditch 'scores' columns   select(     -contains('_scores'), -pca   ) |>    unnest(c(PC1_loadings, PC2_loadings, variable)) |>    rename(     PC1 = PC1_loadings,     PC2 = PC2_loadings   ) |>    mutate(     pattern = case_when(       variable %in% c(\"THOUGHT_F2\", \"STRUT_F2\", \"THOUGHT_F1\", \"START_F2\") ~         \"Back vowel configuration\",       variable %in% c(         \"TRAP_F1\", \"KIT_F2\", \"FLEECE_F1\", \"NURSE_F1\", \"LOT_F2\", \"DRESS_F1\"       ) ~ \"Leader/lagger\",       .default = \"Other\"     )   )  anim <- onze_loadings |>    ggplot(     aes(       x = PC1,       y = PC2,       xend = PC1,       yend = PC2,       label = variable,       group = variable,       colour = pattern     )   ) +   geom_hline(     yintercept = 0,      linewidth = 0.5,     linetype = \"dashed\"   ) +   geom_vline(     xintercept = 0,      linewidth = 0.5,     linetype = \"dashed\"   ) +   geom_segment(     x = 0,      y = 0,      arrow = arrow(),      #show.legend = FALSE,     linewidth = 1.5   ) +   geom_text(     size = 5,      show.legend = FALSE,     nudge_x = 0.05,     nudge_y = 0.05   ) +   scale_colour_manual(     values = c(       \"Leader/lagger\" = \"#F95A5C\",        \"Back vowel configuration\" = \"#425B78\",       \"Other\" = \"grey\"     )   ) +   scale_x_continuous(expand = expansion(mult=0.1)) +   scale_y_continuous(expand = expansion(mult=0.1)) +   theme_minimal() +   theme(     plot.caption = element_text(size = 20),   ) +   labs(     caption = \"Bootstrap: {closest_state}/15\",     colour = \"Vowel pattern\"   ) +   transition_states(     iteration,     transition_length = 4,     state_length = 2   )  animate(anim, nframes = 500)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"manual-rotation","dir":"Articles","previous_headings":"3 Comparing PCA across two data sets > 3.1 Are the same patterns of covariation present in two data sets?","what":"Manual rotation","title":"PCA and Rotation","text":"Sometimes, working two PCs, ’s easiest just decide much want rotate space manually . nzilbb.vowels includes pca_rotate_2d() rotate PCs two dimensions. works output prcomp() princomp(), output pca_test(). Let’s repeat Figure 3.4 prcomp(). Figure 3.6: ONZE QB loadings PC1 PC2 rotation. Let’s align ONZE QB. Visually, can see possible rotating TRAP_F1 along PC1. roughly 90 degree clockwise rotation achieve . Let’s . Figure 3.7: ONZE QB loadings components 1 2, ONZE rotated. Figure 3.7 roughly aligns first component ONZE first PC QB.2 looks like second component similar also flip ONZE second component. Let’s using pc_flip() function. Figure 3.8: ONZE QB loadings components 1 2, ONZE manually rotated flipped Component 2. arguable flip improves things. test using correlations, better switch less impressionistic method. Nonetheless, simple 2D rotations flips, manually applied, sometimes need.","code":"qb_pca <- prcomp(   qb_intercepts |> select(-speaker),   scale = TRUE )  onze_pca <- prcomp(   onze_intercepts_full |> select(-speaker),   scale = TRUE )  loadings_to_plot <- bind_rows(   \"QB\" = as_tibble(qb_pca$rotation, rownames=\"variable\"),   \"ONZE\" = as_tibble(onze_pca$rotation, rownames=\"variable\"),   .id = \"Corpus\" )  loadings_to_plot |>    ggplot(     aes(       xend = PC1,       yend = PC2,       label = variable     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=PC1, y = PC2), size = 2) +   scale_x_continuous(expand = expansion(mult=0.1)) +   facet_grid(cols = vars(Corpus)) onze_rot <- pca_rotate_2d(onze_pca, 90, pcs=c(1,2))  loadings_to_plot <- bind_rows(   \"QB\" = as_tibble(qb_pca$rotation, rownames=\"variable\"),   \"ONZE (Rotated)\" = as_tibble(onze_rot$rotation, rownames=\"variable\"),   .id = \"Corpus\" )  loadings_to_plot |>    ggplot(     aes(       xend = PC1,       yend = PC2,       label = variable     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=PC1, y = PC2), size = 2) +   scale_x_continuous(expand = expansion(mult=0.1)) +   facet_grid(cols = vars(Corpus)) +   labs(     x = \"Component 1\",     y = \"Component 2\"   ) onze_rot <- pc_flip(onze_rot, pc_no=2)  loadings_to_plot <- bind_rows(   \"QB\" = as_tibble(qb_pca$rotation, rownames=\"variable\"),   \"ONZE (Rotated and flipped)\" = as_tibble(onze_rot$rotation, rownames=\"variable\"),   .id = \"Corpus\" )  loadings_to_plot |>    ggplot(     aes(       xend = PC1,       yend = PC2,       label = variable     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=PC1, y = PC2), size = 2) +   scale_x_continuous(expand = expansion(mult=0.1)) +   facet_grid(cols = vars(Corpus)) +   labs(     x = \"Component 1\",     y = \"Component 2\"   )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"procrustes-rotation","dir":"Articles","previous_headings":"3 Comparing PCA across two data sets > 3.1 Are the same patterns of covariation present in two data sets?","what":"Procrustes rotation","title":"PCA and Rotation","text":"Procrustes rotation produces closest alignment two shapes possible using scaling rotation. two shapes must landmarks . case, shape position variables space defined PCs, , loadings.3 Underlying method procrustes() function vegan package. uses PCA NZILBB research programme nzilbb.vowels emerged , close ‘ordination’ methods used community ecology. vegan package community ecology. nzilbb.vowels, hidden options explicitly use language ‘species’ ‘site’. nzilbb.vowels function called pca_rotate_procrustes(). now maximally align QB ONZE PCA analyses using Procrustes rotation. choose many PCs include . purposes illustration, choose first five PCs, ONZE data five statistically significant PCs according pca_test().4 rotate ONZE match QB (easily go way). NB: ensure order variables appear data goes prcomp() across two PCAs. Procrustes function knows Figure 3.9: First two components QB PCA Procrustes rotated ONZE PCA. compare manual rotation tried (Figure 3.8)? Figure 3.10: ONZE PCA rotated manually via Procrustes rotation. biggest difference two approaches Procrustes rotation five dimensional rotation, whereas manual rotation 2D. Information first 5 dimensions picked Procrustes rotation can now appear Component 1 Component 2, aim matching patterns present first five PCs QuakeBox. manual rotation, case, closely match interpretation Component 1 measures something like ‘leader/lagger’ status second component gives us kind change back vowel configuration. unsurprising, interpretation motivated selection manual rotation applied!","code":"onze_proc <- onze_pca |>    pca_rotate_procrustes(target = qb_pca, max_pcs = 5)  loadings_to_plot <- bind_rows(   \"QB\" = as_tibble(qb_pca$rotation, rownames=\"variable\"),   \"ONZE (Rotated)\" = as_tibble(onze_proc$rotation, rownames=\"variable\"),   .id = \"Corpus\" )  loadings_to_plot |>    ggplot(     aes(       xend = PC1,       yend = PC2,       label = variable     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=PC1, y = PC2), size = 2) +   scale_x_continuous(expand = expansion(mult=0.1)) +   facet_grid(cols = vars(Corpus)) +   labs(     x = \"Component 1\",     y = \"Component 2\"   ) loadings_to_plot <- bind_rows(   \"ONZE manual\" = as_tibble(onze_rot$rotation, rownames=\"variable\"),   \"ONZE Procrustes\" = as_tibble(onze_proc$rotation, rownames=\"variable\"),   .id = \"Corpus\" )  loadings_to_plot |>    ggplot(     aes(       xend = PC1,       yend = PC2,       label = variable     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=PC1, y = PC2), size = 2) +   scale_x_continuous(expand = expansion(mult=0.1)) +   facet_grid(cols = vars(Corpus)) +   labs(     x = \"Component 1\",     y = \"Component 2\"   )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"partial-overlap-of-variables-and-rotation-on-scores","dir":"Articles","previous_headings":"3 Comparing PCA across two data sets","what":"Partial overlap of variables and rotation on scores","title":"PCA and Rotation","text":"cases, might partially overlapping variables two PCA analyses. Upcoming work bilingualism faces problem, vowel categories can aligned across languages. special issue manual 2D rotations. problem slightly serious Procrustes rotation. solution work rotation using shared landmarks apply rotation variables. can specify landmarks use via rotation_variables argument pca_rotate_procrustes(). list names variable use vector. implies names variables dataset. ’ll rotate using just DRESS, TRAP, KIT. Figure 3.11: QB1 PCA Procrustes rotated ONZE PCA, rotated respect DRESS, TRAP, KIT . lucky position exact speakers corpora, can rotate scores instead determine happens variables. individuals must order datasets. case QuakeBox ONZE corpora, case subset QuakeBox corpora. Let’s apply procrustes rotation scores look interpretation loadings. apply rotation QB2, using scores . variance explained QB2 PCA? Figure 3.12: Variance explained components Procrustes rotation. Let’s look loadings. Figure 3.13: Loadings first two compnents QB1 PCA rotated QB2 PCA. look similar one another. say maximally align speakers across two datasets space variation, linguistic interpretation variation stays similar. repeat: used Procrustes rotation rotate scores speakers rather loadings variables. looked loadings. much variation scores rotation? Figure 3.14: Change PC scores QB1 QB2, Procrustes rotation. approach work even two datasets variables common.","code":"rot_vars <- c(   \"DRESS_F1\", \"DRESS_F2\", \"TRAP_F1\", \"TRAP_F2\", \"KIT_F1\", \"KIT_F2\" )  onze_proc <- onze_pca |>    pca_rotate_procrustes(     target = qb_pca,      max_pcs = 3, # Exercise: look at what happens when you change this.      rotation_variables = rot_vars   )  loadings_to_plot <- bind_rows(   \"QB\" = as_tibble(qb_pca$rotation, rownames=\"variable\"),   \"ONZE (Rotated)\" = as_tibble(onze_proc$rotation, rownames=\"variable\"),   .id = \"Corpus\" )  loadings_to_plot |>    mutate(     highlight = str_detect(variable, \"(DRESS|TRAP|KIT)\")   ) |>    ggplot(     aes(       xend = PC1,       yend = PC2,       label = variable,       fill = highlight,       colour = highlight     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=PC1, y = PC2), size = 2, colour=\"black\") +   scale_x_continuous(expand = expansion(mult=0.1)) +   scale_fill_manual(     values = c(\"TRUE\" = \"red\", \"FALSE\" = \"grey\")   ) +   scale_colour_manual(     values = c(\"TRUE\" = \"red\", \"FALSE\" = \"grey\")   ) +   facet_grid(cols = vars(Corpus)) +   labs(     x = \"Component 1\",     y = \"Component 2\"   ) +   theme(     legend.position = \"none\"   ) QB1_ints <- read_rds('data/QB1_scores_anon.rds') |>    select(-contains(\"PC\")) QB2_ints <- read_rds('data/QB2_scores_anon.rds')|>    select(-contains(\"PC\")) # get shared speakers between QB1 and QB2 and ensure they are in the same  # order in the data. shared_speakers = intersect(QB1_ints$speaker, QB2_ints$speaker)  QB1_ints <- QB1_ints |>    filter(     speaker %in% shared_speakers   ) |>    arrange(speaker)  QB2_ints <- QB2_ints |>    filter(     speaker %in% shared_speakers   ) |>    arrange(speaker)  QB1_pca <- prcomp(   QB1_ints |> select(-speaker), scale = TRUE )  QB2_pca <- prcomp(   QB2_ints |> select(-speaker), scale = TRUE ) # Here it would be a good idea to determine how many PCs to include via  # `pca_test()`. We skip this detail for now. QB2_proc <- QB2_pca |>    pca_rotate_procrustes(     target = QB1_pca,      max_pcs = 2,     rotate = \"scores\"   ) plot(QB2_proc) loadings_to_plot <- bind_rows(   \"QB1\" = as_tibble(QB1_pca$rotation, rownames=\"variable\"),   \"QB2 (Rotated)\" = as_tibble(QB2_proc$rotation, rownames=\"variable\"),   .id = \"Corpus\" )  loadings_to_plot |>    ggplot(     aes(       xend = PC1,       yend = PC2,       label = variable     )   ) +   geom_segment(x=0, y=0, arrow = arrow(length = unit(2, \"mm\"))) +   geom_label_repel(aes(x=PC1, y = PC2), size = 2) +   scale_x_continuous(expand = expansion(mult=0.1)) +   facet_grid(cols = vars(Corpus)) +   labs(     x = \"Component 1\",     y = \"Component 2\"   ) scores_to_plot <- bind_rows(   \"QB1\" = as_tibble(QB1_pca$x, rownames=\"speaker\"),   \"QB2 (Rotated)\" = as_tibble(QB2_proc$x, rownames=\"speaker\"),   .id = \"Corpus\" )  scores_to_plot |>    ggplot(     aes(       x = PC1,       y = PC2,       group = speaker     )   ) +   geom_vline(xintercept = 0, linewidth = 0.5, linetype = \"dashed\") +   geom_hline(yintercept = 0, linewidth = 0.5, linetype = \"dashed\") +   geom_line(arrow = arrow(length = unit(2, \"mm\"))) +   scale_x_continuous(expand = expansion(mult=0.1)) +   labs(     x = \"Component 1\",     y = \"Component 2\"   )"},{"path":[]},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"manual-rotation-for-interpretability","dir":"Articles","previous_headings":"4 Rotation for single data set","what":"Manual rotation for interpretability","title":"PCA and Rotation","text":"Sometimes interpretability space generated PCA much easier apply rotation. kind move justified interested space captured first \\(n\\) PCs rather PCs . example just looked , can describe X% variation original data describing terms cognitive motor dimension. still impressive even two dimensions aren’t precisely PCs.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/articles/Rotation.html","id":"procrustes-rotation-for-improved-confidence-bars","dir":"Articles","previous_headings":"4 Rotation for single data set","what":"Procrustes rotation for improved confidence bars","title":"PCA and Rotation","text":"can use Procrustes rotation alternative source confidence bars loadings. currently explored alternative filtering bootstraps get cases PCs --less aligned. use Procrustes rotation part bootstrapping common Multidimensional Scaling (MDS). fundamental idea case comparing across two datasets, bootstrap sample distinct dataset (explored ). implement test procrustes_loadings() plot plot_procrustes_loadings(). decide better way go generating confidence bands, eventually merged pca_test() function.5 procrustes_loadings() function takes data usually put prcomp() princomp(). choose number PCs rotate (max_pcs argument). One way make choice use output pca_test() (specifically, number ‘statistically significant’ PCs, determined looking plot variance explained). choose 5 PCs, line Figure 3.3. Let’s generate distribution signed index loadings first 5 PCs, using procrustes_loadings() function ONZE data. procrustes_loadings() function gives signed index loadings PC bootstrapped analyses (value Sampling source column). plot_procrustes_loadings() function can used visualise distribution. Figure 4.1: Index loadings, confidence band, null distribution PC1. default, function uses index loadings (pca_test()). index loadings always positive. rotation make sense, need add sign back index loadings (.e., whether original loading positive negative). can generate confidence intervals original loadings setting index=FALSE. However, set index=FALSE, get estimate null distribution, won’t get kind indication whether loading significant. instance:","code":"onze_loadings <- procrustes_loadings(   onze_intercepts_full |> select(-speaker),   max_pcs = 5,   index = TRUE,   n = 500,   scale = TRUE ) plot_procrustes_loadings(onze_loadings, pc_no=1, loadings_confint = 0.95) onze_loadings <- procrustes_loadings(   onze_intercepts_full |> select(-speaker),   max_pcs = 5,   index = FALSE,   n = 500,   scale = TRUE )  plot_procrustes_loadings(onze_loadings, pc_no=1, loadings_confint = 0.95)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Joshua Wilson Black. Author, maintainer, copyright holder. James Brand. Author.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wilson Black J, Brand J, Hay J, Clark L (2023). “Using Principal Component Analysis Explore Co‐variation Vowels.” Language Linguistics Compass, 17(1), e12479. doi:10.1111/lnc3.12479.","code":"@Article{,   title = {Using Principal Component Analysis to Explore Co‐variation of Vowels},   author = {Joshua {Wilson Black} and James Brand and Jen Hay and Lynn Clark},   journal = {Language and Linguistics Compass},   year = {2023},   volume = {17},   number = {1},   pages = {e12479},   doi = {10.1111/lnc3.12479}, }"},{"path":"https://nzilbb.github.io/nzilbb_vowels/index.html","id":"nzilbbvowels-vowel-covariation-tools-","dir":"","previous_headings":"","what":"Vowel Covariation Tools","title":"Vowel Covariation Tools","text":"nzilbb.vowels packages contains useful functions data investigation vocalic covariation. core package set functions aid PCA-based studies monophthongs. package evolves along ongoing research vocalic covariation carried NZILBB.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Vowel Covariation Tools","text":"Install CRAN:","code":"install.packages('nzilbb.vowels')"},{"path":"https://nzilbb.github.io/nzilbb_vowels/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development version","title":"Vowel Covariation Tools","text":"can install development version nzilbb.vowels GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"nzilbb/nzilbb_vowels\")"},{"path":"https://nzilbb.github.io/nzilbb_vowels/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Vowel Covariation Tools","text":"information, see Wilson Black et al. (2022) associated supplementary material.","code":"library(nzilbb.vowels) #> Loading required package: patchwork ggplot2::theme_set(ggplot2::theme_bw())  # normalise vowels using Lobanov 2.0 normalisation (see Brand et al. (2021)) onze_vowels <- onze_vowels |>    lobanov_2()  # apply PCA to random intercepts from GAMM models (again, from Brand et al. (2021)) onze_pca <- prcomp(   onze_intercepts |> dplyr::select(-speaker),   scale = TRUE )  # Test PCA using bootstrapping approach (see Wilson Black et al. (2022)) onze_pca_test <- pca_test(onze_intercepts |> dplyr::select(-speaker))  # Plot variance explained by each PC. plot_variance_explained(onze_pca_test) # Plot index loadings of PC1 plot_loadings(onze_pca_test) # Plot PC in vowel space plot_pc_vs(onze_vowels, onze_pca_test)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/index.html","id":"rstudio-add-in","dir":"","previous_headings":"","what":"RStudio Add-in","title":"Vowel Covariation Tools","text":"often useful Wells lexical sets small capitals R Markdown documents. way achieve manually add “vowel”. package includes RStudio add , can attached keyboard shortcut. (see ‘Addins’ top RStudio window). add works Quarto RMarkdown files.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/correlation_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Permutation test of pairwise correlations — correlation_test","title":"Permutation test of pairwise correlations — correlation_test","text":"Permute data given number (n) times, collecting pairwise correlations testing significance. See plot_correlation_magnitudes() plot_correlation_counts() plotting functions take output function.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/correlation_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permutation test of pairwise correlations — correlation_test","text":"","code":"correlation_test(pca_data, n = 100, cor.method = \"pearson\")"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/correlation_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permutation test of pairwise correlations — correlation_test","text":"pca_data dataframe matrix containing continuous variables. (accepted prcomp function.) n number times (integer) permute data. Warning: high values take long time compute. Default: 100. cor.method method use correlations (default = \"pearson\"). Alternative \"spearman\" (see ?cor.test).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/correlation_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Permutation test of pairwise correlations — correlation_test","text":"object class correlation_test, attributes: $permuted_correlations tibble length n pairs original data, correlations, significance correlation (p-values). $actual_correlations correlations pair variables original data significance (p-values). $iterations number permutations carried . $cor_method form correlation used.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/correlation_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Permutation test of pairwise correlations — correlation_test","text":"","code":"# get a small sample of random intercepts.   pca_data <- onze_intercepts |>     dplyr::select(-speaker) |>     dplyr::slice_sample(n=10)    # apply correlation test with 5 permutations.   # actual use requires at least 100.   cor_test <- correlation_test(pca_data, n = 5, cor.method = 'pearson')   # Return summary of significant correlations   summary(cor_test) #> Correlation test results. #> Count of significant pairwise correlations in original data at alpha = 0.05: 14 #> Mean significant pairwise correlations in permuted data (n = 5) at alpha = 0.05: 9.6 #> Min = 7, Max = 13. #>  #> Top 5 pairwise correlations in original data: #> F2_LOT, F2_THOUGHT: -0.9 #> F1_GOOSE, F2_START: 0.81 #> F1_GOOSE, F2_THOUGHT: -0.78 #> F2_DRESS, F2_KIT: 0.76 #> F2_FLEECE, F2_NURSE: -0.75    # use spearman correlation instead.   cor_test_spear <- correlation_test(pca_data, n = 10, cor.method = 'spearman')"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/lobanov_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Lobanov 2.0 normalisation — lobanov_2","title":"Apply Lobanov 2.0 normalisation — lobanov_2","text":"lobanov_2() takes data frame first four columns : speaker identifiers, vowel identifiers, first formant values Hertz, second formant values Hertz. returns dataframe two additional columns, F1_lob2 F2_lob2, containing normalised formant values.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/lobanov_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Lobanov 2.0 normalisation — lobanov_2","text":"","code":"lobanov_2(vowel_data)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/lobanov_2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Lobanov 2.0 normalisation — lobanov_2","text":"vowel_data dataframe whose first four columns speaker ids, vowel ids, F1 values, F2 values.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/lobanov_2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Lobanov 2.0 normalisation — lobanov_2","text":"dataframe matching input dataframe additional columns F1_lob2 F2_lob2, containing lobanov normalised F1 F2 values respectively.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/lobanov_2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Lobanov 2.0 normalisation — lobanov_2","text":"functions applies Lobanov 2.0 normalisation presented Brand et al. (2021). variant Lobanov normalisation designed work datasets whether vowel types different token counts one another. Lobanov 2.0 value vowel given $$F_{lobanov2.0_i} = \\frac{F_{raw_i} - \\mu(\\mu_{vowel_1}, \\ldots, \\mu_{vowel_n})}{\\sigma(\\mu_{vowel_1}, \\ldots, \\mu_{vowel_n})}$$ , ease notation, assume values single speaker. signify n vowel types vowel_1, ..., vowel_2, indicates formant number. implement function F1 F2.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/lobanov_2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Apply Lobanov 2.0 normalisation — lobanov_2","text":"Brand, James, Jen Hay, Lynn Clark, Kevin Watson & Márton Sóskuthy (2021): Systematic co-variation monophthongs across speakers New Zealand English. Journal Phonetics. Elsevier. 88. 101096. doi:10.1016/j.wocn.2021.101096","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/lobanov_2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Lobanov 2.0 normalisation — lobanov_2","text":"","code":"normed_vowels <- lobanov_2(onze_vowels) head(normed_vowels) #>    speaker   vowel F1_50 F2_50 speech_rate gender  yob       word     F1_lob2 #> 1 IA_f_065 THOUGHT   514   868      4.3131      F 1891 word_09539 -0.72128947 #> 2 IA_f_065  FLEECE   395  2716      4.3131      F 1891 word_22664 -1.66034667 #> 3 IA_f_065     KIT   653  2413      4.3131      F 1891 word_02705  0.37559246 #> 4 IA_f_065   DRESS   612  2372      4.3131      F 1891 word_23651  0.05205175 #> 5 IA_f_065   GOOSE   445  2037      4.3131      F 1891 word_06222 -1.26578482 #> 6 IA_f_065   GOOSE   443  2258      4.3131      F 1891 word_06222 -1.28156729 #>      F2_lob2 #> 1 -1.9212428 #> 2  1.4915434 #> 3  0.9319794 #> 4  0.8562628 #> 5  0.2376030 #> 6  0.6457338"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/mds_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Test optimal number of MDS dimensions. — mds_test","title":"Test optimal number of MDS dimensions. — mds_test","text":"Generate bootstrapped confidence intervals permutation based null distribution MDS analysis. Output shows much stress reduced adding additional dimension MDS analysis dissimilarity_matrix, bootstrapped iterations dissimilarity_matrix, compared stress reduction expected matrix meaningful structure. function inspired pca_test(), less connected statistical literature function. currently reject additional dimensions reduce less stress expect chance. , distribution boostrapped analyses sits notably lower permuted distribution plotted plot_mds_test()","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/mds_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test optimal number of MDS dimensions. — mds_test","text":"","code":"mds_test(   dissimilarity_matrix,   n_boots = 50,   n_perms = 50,   test_dimensions = 5,   principal = TRUE,   mds_type = \"ordinal\",   spline_degree = 2,   spline_int_knots = 2,   ... )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/mds_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test optimal number of MDS dimensions. — mds_test","text":"dissimilarity_matrix Square matrix dissimilarity scores. n_boots Number bootstrapping iterations (default: 25). n_perms Number permutations (default: 25). test_dimensions Number MDS dimensions test stress reduction (default: 5). principal Whether apply principal axis transform MDS (default: TRUE) mds_type kind MDS apply, see smacof::smacofSym() (default: 'ordinal') spline_degree many spline degrees type 'mspline' (default: 2) spline_int_knots many internal knots type 'mspline' (default: 2) ... Arguments passed smacof::smacofSym()","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/mds_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test optimal number of MDS dimensions. — mds_test","text":"object class mds_test_results, containing: $stress_reduction tibble containing $n_boots Number bootstrapping iterations. $n_perms Number permutation iterations $mds_type Type MDS analysis (type argument passed smacof::smacofSym()) $principal Whether principal axis transformation applied (passed smacof::smacofSym())","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/mds_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test optimal number of MDS dimensions. — mds_test","text":"","code":"# Apply interval MDS to `sim_matrix`, with 5 permutations and bootstraps # testing up to 3 dimensions. In real usage, increase `n_boots` and `n_perms` # to at least 50. mds_test(  smacof::sim2diss(sim_matrix, method=\"reverse\"),  n_boots = 5,  n_perms = 5,  test_dimensions = 3,  mds_type = 'interval' ) #> $stress_reduction #> # A tibble: 33 × 6 #>    source    dims stress_dist cumulative lag_stress  diff #>    <chr>    <int>       <dbl>      <dbl>      <dbl> <dbl> #>  1 permuted     1       0.539          1      1     0.461 #>  2 permuted     1       0.544          2      1     0.456 #>  3 permuted     1       0.543          3      1     0.457 #>  4 permuted     1       0.548          4      1     0.452 #>  5 permuted     1       0.537          5      1     0.463 #>  6 permuted     2       0.363          1      0.539 0.177 #>  7 permuted     2       0.368          2      0.544 0.175 #>  8 permuted     2       0.360          3      0.543 0.182 #>  9 permuted     2       0.363          4      0.548 0.184 #> 10 permuted     2       0.360          5      0.537 0.177 #> # ℹ 23 more rows #>  #> $n_boots #> [1] 5 #>  #> $n_perms #> [1] 5 #>  #> $mds_type #> [1] \"interval\" #>  #> $principal #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"mds_test_results\""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/nzilbb.vowels-package.html","id":null,"dir":"Reference","previous_headings":"","what":"nzilbb.vowels: Vowel Covariation Tools — nzilbb.vowels-package","title":"nzilbb.vowels: Vowel Covariation Tools — nzilbb.vowels-package","text":"Tools support research vowel covariation. Methods provided support Principal Component Analysis workflows (Brand et al. (2021) doi:10.1016/j.wocn.2021.101096  Wilson Black et al. (2023) doi:10.1515/lingvan-2022-0086 ).","code":""},{"path":[]},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/nzilbb.vowels-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nzilbb.vowels: Vowel Covariation Tools — nzilbb.vowels-package","text":"Maintainer: Joshua Wilson Black joshua@wilsonblack.nz (ORCID) [copyright holder] Authors: James Brand james.brand.ac@gmail.com (ORCID)","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts.html","id":null,"dir":"Reference","previous_headings":"","what":"Speaker random intercepts from GAMMs for 100 ONZE speakers — onze_intercepts","title":"Speaker random intercepts from GAMMs for 100 ONZE speakers — onze_intercepts","text":"dataset containing speaker intercepts extracted GAMM models fit Brand et al. (2021).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Speaker random intercepts from GAMMs for 100 ONZE speakers — onze_intercepts","text":"","code":"onze_intercepts"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Speaker random intercepts from GAMMs for 100 ONZE speakers — onze_intercepts","text":"data frame 100 rows 21 variables: speaker Anonymised speaker code (character). F1_DRESS Speaker intercept GAMM model DRESS F1. F2_DRESS Speaker intercept GAMM model DRESS F2. F1_FLEECE Speaker intercept GAMM model FLEECE F1. F2_FLEECE Speaker intercept GAMM model FLEECE F2. F1_GOOSE Speaker intercept GAMM model GOOSE F1. F2_GOOSE Speaker intercept GAMM model GOOSE F2. F1_KIT Speaker intercept GAMM model KIT F1. F2_KIT Speaker intercept GAMM model KIT F2. F1_LOT Speaker intercept GAMM model LOT F1. F2_LOT Speaker intercept GAMM model LOT F2. F1_NURSE Speaker intercept GAMM model NURSE F1. F2_NURSE Speaker intercept GAMM model NURSE F2. F1_START Speaker intercept GAMM model START F1. F2_START Speaker intercept GAMM model START F2. F1_STRUT Speaker intercept GAMM model STRUT F1. F2_STRUT Speaker intercept GAMM model STRUT F2. F1_THOUGHT Speaker intercept GAMM model THOUGHT F1. F2_THOUGHT Speaker intercept GAMM model THOUGHT F2. F1_TRAP Speaker intercept GAMM model TRAP F1. F2_TRAP Speaker intercept GAMM model TRAP F2.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Speaker random intercepts from GAMMs for 100 ONZE speakers — onze_intercepts","text":"https://osf.io/q4j29/","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Speaker random intercepts from GAMMs for 100 ONZE speakers — onze_intercepts","text":"Brand, James, Jen Hay, Lynn Clark, Kevin Watson & Márton Sóskuthy (2021): Systematic co-variation monophthongs across speakers New Zealand English. Journal Phonetics. Elsevier. 88. 101096. doi:10.1016/j.wocn.2021.101096","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Speaker random intercepts for 418 ONZE speakers — onze_intercepts_full","title":"Speaker random intercepts for 418 ONZE speakers — onze_intercepts_full","text":"dataset containing speaker intercepts extracted GAMM models fit Brand et al. (2021).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Speaker random intercepts for 418 ONZE speakers — onze_intercepts_full","text":"","code":"onze_intercepts_full"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts_full.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Speaker random intercepts for 418 ONZE speakers — onze_intercepts_full","text":"data frame 481 rows 21 variables: speaker Anonymised speaker code. F1_DRESS Speaker intercept GAMM model DRESS F1. F2_DRESS Speaker intercept GAMM model DRESS F2. F1_FLEECE Speaker intercept GAMM model FLEECE F1. F2_FLEECE Speaker intercept GAMM model FLEECE F2. F1_GOOSE Speaker intercept GAMM model GOOSE F1. F2_GOOSE Speaker intercept GAMM model GOOSE F2. F1_KIT Speaker intercept GAMM model KIT F1. F2_KIT Speaker intercept GAMM model KIT F2. F1_LOT Speaker intercept GAMM model LOT F1. F2_LOT Speaker intercept GAMM model LOT F2. F1_NURSE Speaker intercept GAMM model NURSE F1. F2_NURSE Speaker intercept GAMM model NURSE F2. F1_START Speaker intercept GAMM model START F1. F2_START Speaker intercept GAMM model START F2. F1_STRUT Speaker intercept GAMM model STRUT F1. F2_STRUT Speaker intercept GAMM model STRUT F2. F1_THOUGHT Speaker intercept GAMM model THOUGHT F1. F2_THOUGHT Speaker intercept GAMM model THOUGHT F2. F1_TRAP Speaker intercept GAMM model TRAP F1. F2_TRAP Speaker intercept GAMM model TRAP F2.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts_full.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Speaker random intercepts for 418 ONZE speakers — onze_intercepts_full","text":"https://osf.io/q4j29/","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_intercepts_full.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Speaker random intercepts for 418 ONZE speakers — onze_intercepts_full","text":"Brand, James, Jen Hay, Lynn Clark, Kevin Watson & Márton Sóskuthy (2021): Systematic co-variation monophthongs across speakers New Zealand English. Journal Phonetics. Elsevier. 88. 101096. doi:10.1016/j.wocn.2021.101096","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels.html","id":null,"dir":"Reference","previous_headings":"","what":"Monophthong data for random sample of speakers from the ONZE corpus — onze_vowels","title":"Monophthong data for random sample of speakers from the ONZE corpus — onze_vowels","text":"dataset containing first second formants, speech rate, gender, year birth 100 random speakers ONZE corpus. 50 speakers sampled birth years 1900 50 sampled birth years 1900 ensure full span time period. Data present following NZE monophthongs, represented Wells lexical sets: DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP. Data FOOT excluded due low token counts.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monophthong data for random sample of speakers from the ONZE corpus — onze_vowels","text":"","code":"onze_vowels"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Monophthong data for random sample of speakers from the ONZE corpus — onze_vowels","text":"dataframe 101572 rows 8 variables: speaker Anonymised speaker code (factor). vowel Variable Wells lexical sets 10 NZE monophthongs. Levels:  DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP (factor). F1_50 First formant, extracted vowel mid-point using LaBB-CAT interface Praat. F2_50 Second formant, extracted vowel mid-point using LaBB-CAT interface Praat. speech_rate Average speaker speech rate whole recording. gender Gender speaker, two levels: \"M\", \"F\" (factor). yob Year birth speaker. word Anonymised word code (factor).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Monophthong data for random sample of speakers from the ONZE corpus — onze_vowels","text":"https://osf.io/q4j29/","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monophthong data for random sample of speakers from the ONZE corpus — onze_vowels","text":"dataset derived data made available supplementary materials Brand et al. (2021).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Monophthong data for random sample of speakers from the ONZE corpus — onze_vowels","text":"Brand, James, Jen Hay, Lynn Clark, Kevin Watson & Márton Sóskuthy (2021): Systematic co-variation monophthongs across speakers New Zealand English. Journal Phonetics. Elsevier. 88. 101096. doi:10.1016/j.wocn.2021.101096","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Monophthong data for speakers from the ONZE corpus — onze_vowels_full","title":"Monophthong data for speakers from the ONZE corpus — onze_vowels_full","text":"dataset containing first second formants, speech rate, gender, year birth 481 speakers ONZE corpus. 50 speakers sampled birth years 1900 50 sampled birth years 1900 ensure full span time period. Data present following NZE monophthongs, represented Wells lexical sets: DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP. Data FOOT excluded due low token counts.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monophthong data for speakers from the ONZE corpus — onze_vowels_full","text":"","code":"onze_vowels_full"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels_full.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Monophthong data for speakers from the ONZE corpus — onze_vowels_full","text":"data frame 414679 rows 8 variables: speaker Anonymised speaker code (factor). vowel Variable Wells lexical sets 10 NZE monophthongs. Levels:  DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP (factor). F1_50 First formant, extracted vowel mid-point using LaBB-CAT interface Praat. F2_50 Second formant, extracted vowel mid-point using LaBB-CAT interface Praat. speech_rate Average speaker speech rate whole recording. gender Gender speaker, two levels: \"M\", \"F\" (factor). yob Year birth speaker. word Anonymised word code (factor).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels_full.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Monophthong data for speakers from the ONZE corpus — onze_vowels_full","text":"https://osf.io/q4j29/","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels_full.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monophthong data for speakers from the ONZE corpus — onze_vowels_full","text":"dataset derived data made available supplementary materials Brand et al. (2021).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/onze_vowels_full.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Monophthong data for speakers from the ONZE corpus — onze_vowels_full","text":"Brand, James, Jen Hay, Lynn Clark, Kevin Watson & Márton Sóskuthy (2021): Systematic co-variation monophthongs across speakers New Zealand English. Journal Phonetics. Elsevier. 88. 101096. doi:10.1016/j.wocn.2021.101096","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pc_flip.html","id":null,"dir":"Reference","previous_headings":"","what":"Flip PC loadings — pc_flip","title":"Flip PC loadings — pc_flip","text":"sign loadings scores generated PCA arbitrary. Sometimes convenient flip positive loadings/scores become negative (vice versa). Sometimes one direction leads natural interpretation. also useful comparing results PCA across multiple data sets. function flip loadings scores PCA analyses carried base R prcomp() princomp() functions pca_test() function package. specify pc_no flip loadings scores PC. can also specify variable like positive loading resulting PCA.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pc_flip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flip PC loadings — pc_flip","text":"","code":"pc_flip(pca_obj, pc_no, flip_var = NULL)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pc_flip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flip PC loadings — pc_flip","text":"pca_obj result call prcomp(), princomp() pca_test. pc_no integer, indicating PC flipped. flip_var optional name variable become positive PC indicated pc_no.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pc_flip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flip PC loadings — pc_flip","text":"object matching class pca_obj relevant PC modified.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pc_flip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flip PC loadings — pc_flip","text":"","code":"pca_obj <- prcomp(onze_intercepts |> dplyr::select(-speaker), scale=TRUE)    # flip the second PC   flipped_pca <- pc_flip(pca_obj, pc_no = 2)    # flip (if necessary) the third PC, so that the \"F1_GOOSE\" variable has   # a positive loading   flipped_pca <- pc_flip(pca_obj, pc_no = 3, flip_var = \"F1_GOOSE\")"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_contrib_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"PCA contribution plots — pca_contrib_plot","title":"PCA contribution plots — pca_contrib_plot","text":"Plot contribution variable data set given Principal Component (PC). Variables arranged ascending contribution PC, contribution squared loading variable expressed percentage. plots match given supplementary material Brand et al. (2021).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_contrib_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PCA contribution plots — pca_contrib_plot","text":"","code":"pca_contrib_plot(pca_object, pc_no = 1, cutoff = 50)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_contrib_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PCA contribution plots — pca_contrib_plot","text":"pca_object pca object generated prcomp princomp. pc_no PC visualised. Default value 1. cutoff cutoff value interpretation PC. Determines total percentage contribution want variables select interpretation. default 50 means pick variables highest contribution PC accounted 50% total contributions PC. Can set NULL case, cutoff value plotted.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_contrib_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PCA contribution plots — pca_contrib_plot","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_contrib_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PCA contribution plots — pca_contrib_plot","text":"plotting functions package, result ggplot2 plot. can modified using ggplot2 functions (see, e.g., plot_correlation_magnitudes().","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_contrib_plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"PCA contribution plots — pca_contrib_plot","text":"Brand, James, Jen Hay, Lynn Clark, Kevin Watson & Márton Sóskuthy (2021): Systematic co-variation monophthongs across speakers New Zealand English. Journal Phonetics. Elsevier. 88. 101096. doi:10.1016/j.wocn.2021.101096","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_contrib_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PCA contribution plots — pca_contrib_plot","text":"","code":"onze_pca <- prcomp(onze_intercepts |> dplyr::select(-speaker), scale = TRUE)    # Plot PC1 with a cutoff value of 60%   pca_contrib_plot(onze_pca, pc_no = 1, cutoff = 60)     # Plot PC2 with no cutoff value.   pca_contrib_plot(onze_pca, pc_no = 2, cutoff = NULL)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Manually rotate two PCs around the origin — pca_rotate_2d","title":"Manually rotate two PCs around the origin — pca_rotate_2d","text":"sometimes convenient rotate principal components closely align sensible interpretation terms original variables compare results PCA applied two distinct datasets. function allows manual 2D rotations principal components.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manually rotate two PCs around the origin — pca_rotate_2d","text":"","code":"pca_rotate_2d(pca_obj, angle, pcs = c(1, 2))"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manually rotate two PCs around the origin — pca_rotate_2d","text":"pca_obj result call prcomp() princomp(). NB make sense apply function output pca_test. angle number indicating number degrees rotate around origin clockwise. Negative values rotated counterclockwise. pcs two-element vector identifying two PCs rotate.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manually rotate two PCs around the origin — pca_rotate_2d","text":"object matching class pca_obj loadings, scores, variance explained component modified.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Manually rotate two PCs around the origin — pca_rotate_2d","text":"NB: rotated components principal components. longer explain maximal variance. Rotated components referred 'principal components'. simplest approach just call 'components' describing rotation. function modifies objects class 'prcomp' 'princomp', adding additional 'note' collects rotations applied. allows plotting function works outputs prcomp() princomp() work. may result plots incorrectly identify rotated components principal components. careful include plot research output.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manually rotate two PCs around the origin — pca_rotate_2d","text":"","code":"pca_obj <- prcomp(onze_intercepts |> dplyr::select(-speaker), scale=TRUE)    # Rotate PCs 3 and 6 by 10 degrees.   rotated_pca <- pca_rotate_2d(pca_obj, 10, pcs = c(3,6))"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_procrustes.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Procrustes rotation to PCA loadings and scores. — pca_rotate_procrustes","title":"Apply Procrustes rotation to PCA loadings and scores. — pca_rotate_procrustes","text":"sometimes convenient rotate principal components align PCA applied one dataset PCA applied another. function allows Procrustes rotation Principal Components, without scaling. , rotate /flip loadings scores PCA analyses rotated closely matches loadings (scores) target PCA analysis.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_procrustes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Procrustes rotation to PCA loadings and scores. — pca_rotate_procrustes","text":"","code":"pca_rotate_procrustes(   to_rotate,   target,   max_pcs,   rotate = \"loadings\",   rotation_variables = \"all\" )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_procrustes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Procrustes rotation to PCA loadings and scores. — pca_rotate_procrustes","text":"to_rotate object class princomp prcomp. target object class princomp prcomp max_pcs integer. Rotation applied PC1 max_pcs. rotate string, either \"loadings\" \"scores\", identify whether loadings to_rotate aligned target scores (default: \"loadings\") rotation_variables string, names variables used rotation. Applied rotation loadings two datasets partial overlap variables. (default: \"\", uses variables).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_procrustes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Procrustes rotation to PCA loadings and scores. — pca_rotate_procrustes","text":"object matching class to_rotate.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_procrustes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Procrustes rotation to PCA loadings and scores. — pca_rotate_procrustes","text":"NB: rotated components principal components. longer explain maximal variance. Rotated components referred 'principal components'. simplest approach just call 'components' describing rotation. function modifies objects class 'prcomp' 'princomp', adding additional 'note' collects rotations applied. allows plotting function works outputs prcomp() princomp() work. may result plots incorrectly identify rotated components principal components. careful include plot research output.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_rotate_procrustes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Procrustes rotation to PCA loadings and scores. — pca_rotate_procrustes","text":"","code":"# PCA on a subset of ONZE speakers   onze_pca <- prcomp(     onze_intercepts |> dplyr::select(-speaker),     scale = TRUE    )     # PCA on all ONZE speakers    onze_full <- prcomp(     onze_intercepts_full |> dplyr::select(-speaker),     scale = TRUE    )     # rotate subset to match loadings of `onze_full`    rotated_pca <- onze_pca |>      pca_rotate_procrustes(        onze_full, max_pcs = 5      )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_test.html","id":null,"dir":"Reference","previous_headings":"","what":"PCA with confidence intervals and null distributions — pca_test","title":"PCA with confidence intervals and null distributions — pca_test","text":"Permute bootstrap data fed PCA n times. Bootstrapped data used estimate confidence bands variance explained PC loading. Squared loadings multiplied squared eigenvalue relevant PC. ranks loadings PCs explain lot variance higher PCs explain less. approach PCA testing follows Carmago (2022) Vieria (2012). approach differs Carmago's PCAtest package separating data generation plotting.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PCA with confidence intervals and null distributions — pca_test","text":"","code":"pca_test(   pca_data,   n = 100,   scale = TRUE,   variance_confint = 0.95,   loadings_confint = 0.9 )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PCA with confidence intervals and null distributions — pca_test","text":"pca_data data fed prcomp function. n number times permute bootstrap data. Warning: high values take long time compute. scale whether PCA variables scaled (default: TRUE). variance_confint size confidence intervals variance explained (default: 0.95). loadings_confint size confidence intervals index loadings (default: 0.9).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PCA with confidence intervals and null distributions — pca_test","text":"object class pca_test_results, containing: $variance tibble containing variances explained confidence intervals PC. $loadings tibble containing index loadings confidence intervals variable PC. $raw_data tibble containing variance explained loadings bootstrapped permuted analysis. $variance_confint confidence intervals applied variance explained. $loadings_confint confidence interval applied loadings. $n number iterations permutation bootstrapping.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PCA with confidence intervals and null distributions — pca_test","text":"Default confidence bands variance explained 0.95 (.e. alpha 0.05). line Vieria (2012), default confidence bands index loadings 0.9. See plot_loadings() plot_variance_explained() useful plotting functions.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"PCA with confidence intervals and null distributions — pca_test","text":"Camargo, Arley (2022), PCAtest: testing statistical significance Principal Component Analysis R. PeerJ 10. e12967. doi:10.7717/peerj.12967 Vieira, Vasco (2012): Permutation tests estimate significances Principal Components Analysis. Computational Ecology Software 2. 103–123.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/pca_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PCA with confidence intervals and null distributions — pca_test","text":"","code":"onze_pca <- pca_test(   onze_intercepts |> dplyr::select(-speaker),   n = 10,   scale = TRUE ) summary(onze_pca) #> PCA Permutation and Bootstrapping Test #>  #> Iterations: 10 #>  #> Significant PCs at 0.05 level: PC1, PC2, PC3, PC4, PC5. #>  #> Significant loadings at 0.1 level:  #> \tPC1: F1_FLEECE #> \tPC1: F1_GOOSE #> \tPC1: F1_START #> \tPC1: F1_THOUGHT #> \tPC1: F1_TRAP #> \tPC1: F2_FLEECE #> \tPC1: F2_NURSE #> \tPC1: F2_STRUT #> \tPC1: F2_THOUGHT #> \tPC2: F1_DRESS #> \tPC2: F1_FLEECE #> \tPC2: F1_NURSE #> \tPC2: F2_DRESS #> \tPC2: F2_KIT #> \tPC2: F2_LOT #> \tPC2: F2_STRUT #> \tPC2: F2_THOUGHT #> \tPC2: F2_TRAP #> \tPC3: F2_GOOSE #> \tPC3: F2_LOT #> \tPC3: F2_NURSE #> \tPC4: F1_KIT #> \tPC4: F1_LOT #> \tPC5: F1_STRUT #> \tPC5: F2_KIT #> \tPC5: F2_START #> \tPC5: F2_STRUT #> \tPC6: F1_DRESS #> \tPC6: F1_NURSE #> \tPC6: F2_START #> \tPC8: F1_KIT #> \tPC9: F1_LOT #> \tPC10: F1_THOUGHT #> \tPC11: F2_DRESS"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/permutation_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Run permutation test on PCA analysis. — permutation_test","title":"Run permutation test on PCA analysis. — permutation_test","text":"Permute data fed PCA given number times, collecting number significant pairwise correlations permuted data variances explained given number PCs.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/permutation_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run permutation test on PCA analysis. — permutation_test","text":"","code":"permutation_test(   pca_data,   pc_n = 5,   n = 100,   scale = TRUE,   cor.method = \"pearson\" )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/permutation_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run permutation test on PCA analysis. — permutation_test","text":"pca_data data fed prcomp function. Remove non-continuous variables. pc_n number PCs collect variance explained . n number times permute data. Warning: high values take long time compute. scale whether PCA variables scaled (default = TRUE). cor.method method use correlations (default = \"pearson\"). Alternative \"spearman\".","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/permutation_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run permutation test on PCA analysis. — permutation_test","text":"object class permutation_test $permuted_variances n x pc_no matrix variances explained first pc_no PCs n permutations original data. $permuted_correlations list length n significant pairwise correlations n permutations data (<= 0.05). $actual_variances pc_n x 2 tibble variances explained first pc_n PCs original data. $actual_correlations number significant pairwise correlations (<= 0.05) original data.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/permutation_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run permutation test on PCA analysis. — permutation_test","text":"function now superseded. Use correlation_test() pairwise correlations pca_test() variance explained loadings.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/permutation_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run permutation test on PCA analysis. — permutation_test","text":"","code":"permutation_test(   onze_intercepts |> dplyr::select(-speaker),   pc_n = 5,   n = 10,   scale = TRUE,   cor.method = 'pearson'  ) #> $permuted_variances #>           PC1        PC2        PC3        PC4        PC5 #> 1  0.09749977 0.08053709 0.07490254 0.06797534 0.06582942 #> 2  0.09614605 0.08862427 0.08143212 0.07125520 0.06540196 #> 3  0.09601274 0.08743422 0.08462001 0.07458940 0.06959122 #> 4  0.10227363 0.08548202 0.07840330 0.07660964 0.06972533 #> 5  0.09894546 0.08231594 0.07032241 0.06761381 0.06585873 #> 6  0.09676498 0.08792137 0.08101650 0.07176972 0.06380875 #> 7  0.10345031 0.08843245 0.08033364 0.07595603 0.07250766 #> 8  0.09447521 0.08765234 0.07978291 0.06734720 0.06584082 #> 9  0.09355401 0.08811057 0.07823286 0.07236188 0.06886634 #> 10 0.08942127 0.08622782 0.07959623 0.07777337 0.06815037 #>  #> $permuted_correlations #>  [1]  4 11 13 10  7 10 13  7  8 11 #>  #> $actual_variances #> # A tibble: 5 × 2 #>   PC    variance_explained #>   <chr>              <dbl> #> 1 PC1               0.183  #> 2 PC2               0.143  #> 3 PC3               0.0989 #> 4 PC4               0.0835 #> 5 PC5               0.0774 #>  #> $actual_correlations #> [1] 69 #>  #> attr(,\"class\") #> [1] \"permutation_results\""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of correlation counts from correlation_test object — plot_correlation_counts","title":"Plot of correlation counts from correlation_test object — plot_correlation_counts","text":"Plot number statistically significant pairwise correlations data set given alpha value distribution counts statistically significant pairwise correlations permuted data. informal test useful convincing structure data PCA might able uncover.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of correlation counts from correlation_test object — plot_correlation_counts","text":"","code":"plot_correlation_counts(cor_test, alpha = 0.05, half_violin = FALSE)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of correlation counts from correlation_test object — plot_correlation_counts","text":"cor_test object class correlation_test generated correlation_test. alpha significance level counting correlation significant. half_violin Plot correlation counts using half violin plot half point plot. Quantiles currently supported.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot of correlation counts from correlation_test object — plot_correlation_counts","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_counts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot of correlation counts from correlation_test object — plot_correlation_counts","text":"resulting plot presents distribution counts statistically significant correlations given alpha level permuted data count statistically significant correlations original data. red dot uppermost line inside blue violin plot, say number statistically significant correlations real data statistically significant. Usually used rough sanity check course PCA workflow want see red dot well violin (example ). resulting plot ggplot2 plot can modified using functions package. instance, titles can removed using ggplot2::labs() function (examples ).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of correlation counts from correlation_test object — plot_correlation_counts","text":"","code":"# Test correlations (use at least n = 100)   cor_test <- correlation_test(onze_intercepts |>     dplyr::select(-speaker), n = 10)   cor_plot <- plot_correlation_counts(cor_test)   cor_plot     # make statistical test more strict by reducing the alpha.   cor_plot_strict <- plot_correlation_counts(cor_test, alpha = 0.01)    # modify plot using `ggplot2` functions, e.g.   cor_plot_strict +     ggplot2::labs(title = NULL) +     ggplot2::theme_bw()"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_magnitudes.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot distribution of correlations from correlation_test object — plot_correlation_magnitudes","title":"Plot distribution of correlations from correlation_test object — plot_correlation_magnitudes","text":"plot type used Brand et al. (2021). presents magnitudes correlations real data solid red line, correlations iteration permutation test light blue lines. gives visual sense distribution random correlations compared actual data. significant pairwise correlations data, thick red line visually lower wider across plot thinner blue lines. significant pairwise correlations, thick red line shape blue lines.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_magnitudes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot distribution of correlations from correlation_test object — plot_correlation_magnitudes","text":"","code":"plot_correlation_magnitudes(cor_test)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_magnitudes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot distribution of correlations from correlation_test object — plot_correlation_magnitudes","text":"cor_test object class correlation_test generated correlation_test.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_magnitudes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot distribution of correlations from correlation_test object — plot_correlation_magnitudes","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_magnitudes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot distribution of correlations from correlation_test object — plot_correlation_magnitudes","text":"Brand, James, Jen Hay, Lynn Clark, Kevin Watson & Márton Sóskuthy (2021): Systematic co-variation monophthongs across speakers New Zealand English. Journal Phonetics. Elsevier. 88. 101096. doi:10.1016/j.wocn.2021.101096","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_correlation_magnitudes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot distribution of correlations from correlation_test object — plot_correlation_magnitudes","text":"","code":"# Test correlations (use at least n = 100)   cor_test <- correlation_test(onze_intercepts |>     dplyr::select(-speaker), n = 10)   cor_plot <- plot_correlation_magnitudes(cor_test)   cor_plot     # modify plot using `ggplot2` functions, e.g.   cor_plot +     ggplot2::labs(title = NULL) +     ggplot2::theme_bw()"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot PC index loadings from pca_test object. — plot_loadings","title":"Plot PC index loadings from pca_test object. — plot_loadings","text":"Index loadings (Vieira 2012) presented confidence intervals sampling distribution generated bootstrapping null distribution generated permutation.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot PC index loadings from pca_test object. — plot_loadings","text":"","code":"plot_loadings(   pca_test,   pc_no = 1,   violin = FALSE,   filter_boots = FALSE,   quantile_threshold = 0.25 )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot PC index loadings from pca_test object. — plot_loadings","text":"pca_test object class pca_test_results generated pca_test. pc_no integer indicating PC plot. violin TRUE, violin plots added confidence intervals sampling distribution. filter_boots TRUE, bootstrap iterations variable highest median loading quantile_threshold. quantile_threshold real value 0 1. Use change threshold used filtering bootstrap iterations. default 0.25.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot PC index loadings from pca_test object. — plot_loadings","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_loadings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot PC index loadings from pca_test object. — plot_loadings","text":"PCs unstable, option (filter_boots) take bootstrap iterations variable highest median loading across iterations quantile_threshold (default: 0.25). helps reveal reliable connections variable variables data set.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_loadings.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot PC index loadings from pca_test object. — plot_loadings","text":"Vieira, Vasco (2012): Permutation tests estimate significances Principal Components Analysis. Computational Ecology Software 2. 103–123.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_loadings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot PC index loadings from pca_test object. — plot_loadings","text":"","code":"onze_pca <- pca_test(onze_intercepts |> dplyr::select(-speaker), n = 10)   # Plot PC1   plot_loadings(onze_pca, pc_no=1)    # Plot PC2 with violins (not particularly useful in this case!)   plot_loadings(onze_pca, pc_no=2, violin = TRUE)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_mds_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mds_test() results — plot_mds_test","title":"Plot mds_test() results — plot_mds_test","text":"Plot output mds_test().","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_mds_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mds_test() results — plot_mds_test","text":"","code":"plot_mds_test(mds_test)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_mds_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mds_test() results — plot_mds_test","text":"mds_test Object class mds_test_results (generated mds_test()).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_mds_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot mds_test() results — plot_mds_test","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_mds_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot mds_test() results — plot_mds_test","text":"","code":"mds_result <- mds_test(     sim_matrix,     n_boots = 10,     n_perms = 10,     test_dimensions = 3,     mds_type = 'interval'  )  plot_mds_test(mds_result)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Scores from Significant PCs Against PCA Input — plot_pc_input","title":"Plot Scores from Significant PCs Against PCA Input — plot_pc_input","text":"sometimes useful see relationship PCs raw values input data fed PCA. function takes results running pca_test, scores speaker pca object, raw data fed PCA analysis. usual model--pca analysis pipeline, resulting plot depicts -speaker random intercepts vowel indication variables significantly loaded onto PCs. allows researcher visualise strength relationship intercepts PC scores.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Scores from Significant PCs Against PCA Input — plot_pc_input","text":"","code":"plot_pc_input(pca_object, pca_data, pca_test)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Scores from Significant PCs Against PCA Input — plot_pc_input","text":"pca_object Output prcomp. pca_data Data fed prcomp. include speaker identifiers. pca_test Output pca_test","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Scores from Significant PCs Against PCA Input — plot_pc_input","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_input.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Scores from Significant PCs Against PCA Input — plot_pc_input","text":"","code":"pca_data <- onze_intercepts |> dplyr::select(-speaker) onze_pca <- prcomp(pca_data, scale = TRUE) onze_pca_test <- pca_test(pca_data, n = 5) # Increase n to at least 100 in practice. plot_pc_input(onze_pca, pca_data, onze_pca_test) #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_vs.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot PC loadings in vowel space — plot_pc_vs","title":"Plot PC loadings in vowel space — plot_pc_vs","text":"Plot loadings PCA analysis carried vocalic data. Vowel positions mean values mean arrows indicating loadings. Loadings multiplied standard deviation, vowel, initial input data. OK getting quick, intuitive, interpretation PCs mean vowel space. using model--PCA pipeline, recommended use plots directly publications models reliably control variation vocalic readings taking standard mean standard deviation.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_vs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot PC loadings in vowel space — plot_pc_vs","text":"","code":"plot_pc_vs(vowel_data, pca_obj, pc_no = 1, is_sig = FALSE)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_vs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot PC loadings in vowel space — plot_pc_vs","text":"vowel_data dataframe whose first four columns speaker ids, vowel ids, F1 values, F2 values. pca_obj result call prcomp(), princomp() pca_test(). pc_no integer, indicating PC plot (default PC1). is_sig boolean, indicating whether 'significant' loadings, according pca_test plotted (works objects class pca_test_results).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_vs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot PC loadings in vowel space — plot_pc_vs","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_pc_vs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot PC loadings in vowel space — plot_pc_vs","text":"","code":"onze_pca <- prcomp(onze_intercepts |> dplyr::select(-speaker), scale=TRUE)   # Default is to plot PC1   plot_pc_vs(onze_vowels, onze_pca)    # Or plot another PC with `pc_no`   plot_pc_vs(onze_vowels, onze_pca, pc_no = 3)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_permutation_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Create plot from permutation_test(). — plot_permutation_test","title":"Create plot from permutation_test(). — plot_permutation_test","text":"Plots results permutation test carried permutation_test() function. Now use either correlation_test() pca_test() associated plotting functions.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_permutation_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create plot from permutation_test(). — plot_permutation_test","text":"","code":"plot_permutation_test(permutation_results, violin = FALSE)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_permutation_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create plot from permutation_test(). — plot_permutation_test","text":"permutation_results object class permutation_results. violin Determines whether variances explained depicted distinct violin plots PC connected lines. advantage lines correctly indicate values PC depend one another within given permutation. , earlier PC soaks lot variation data set, less variation left explain subsequent PCs. Default value FALSE.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_permutation_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create plot from permutation_test(). — plot_permutation_test","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_permutation_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create plot from permutation_test(). — plot_permutation_test","text":"","code":"onze_perm <- permutation_test(   onze_intercepts |> dplyr::select(-speaker),   pc_n = 5,   n = 10,   scale = TRUE,   cor.method = 'pearson'  ) plot_permutation_test(onze_perm)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_procrustes_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot loadings with confidence bands from procrustes_loadings() — plot_procrustes_loadings","title":"Plot loadings with confidence bands from procrustes_loadings() — plot_procrustes_loadings","text":"Plot index loadings loadings confidence intervals null distributions generated bootstrapping permutation followed Procrustes rotation. approach works PC loadings unstable due multiple PCs explaining similar amounts variance. alternative use bootstrapping without Procrustes rotation (pca_test()) avoids need use filter_boots argument plot_loadings().","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_procrustes_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot loadings with confidence bands from procrustes_loadings() — plot_procrustes_loadings","text":"","code":"plot_procrustes_loadings(proc_loadings, pc_no = 1, loadings_confint = 0.9)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_procrustes_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot loadings with confidence bands from procrustes_loadings() — plot_procrustes_loadings","text":"proc_loadings tibble, generated procrustes_loadings() pc_no integer indicating PC plot. loadings_confint confidence limits generated confidence intervals. (default: 0.9 match pca_test()).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_procrustes_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot loadings with confidence bands from procrustes_loadings() — plot_procrustes_loadings","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_procrustes_loadings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot loadings with confidence bands from procrustes_loadings() — plot_procrustes_loadings","text":"","code":"proc_loadings <- procrustes_loadings(     pca_data = onze_intercepts |> dplyr::select(-speaker),     max_pcs = 3,     index = TRUE,     n = 10, # set this to at least 100 in actual use.     scale = TRUE    )     plot_procrustes_loadings(proc_loadings, pc_no = 2)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_variance_explained.html","id":null,"dir":"Reference","previous_headings":"","what":"Create plot of variances explained from pca_test object — plot_variance_explained","title":"Create plot of variances explained from pca_test object — plot_variance_explained","text":"variance explained PC dataset plotted confidence intervals generated bootstrapping null distribution generated permutation. function accepts result calling pca_test function.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_variance_explained.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create plot of variances explained from pca_test object — plot_variance_explained","text":"","code":"plot_variance_explained(pca_test, pc_max = NA, percent = TRUE)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_variance_explained.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create plot of variances explained from pca_test object — plot_variance_explained","text":"pca_test object class pca_test_results generated pca_test. pc_max maximum number PCs plot. NA, plot PCs. percent TRUE, represent variance explained percentage. FALSE, represent eigenvalues.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_variance_explained.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create plot of variances explained from pca_test object — plot_variance_explained","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_variance_explained.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create plot of variances explained from pca_test object — plot_variance_explained","text":"default, variance explained represented percentage. argument percent set FALSE, variance explained represented eigenvalues corresponding PC.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_variance_explained.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create plot of variances explained from pca_test object — plot_variance_explained","text":"","code":"onze_pca <- pca_test(onze_intercepts |> dplyr::select(-speaker), n = 10)   # Plot with percentages   plot_variance_explained(onze_pca)    # Plot with eigenvalues and only the first 5 PCs.   plot_variance_explained(onze_pca, pc_max = 5, percent = FALSE)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_vowel_space.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot vowel space for speaker or speakers. — plot_vowel_space","title":"Plot vowel space for speaker or speakers. — plot_vowel_space","text":"Given vowel data first column identifying speakers, second identifying vowels, third containing F1 fourth containing F2 values, plot vowel space using speaker's mean values vowel. Typically best produce plot scratch. primary purpose function generate quick plots interactive use, rather produce plots publication.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_vowel_space.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot vowel space for speaker or speakers. — plot_vowel_space","text":"","code":"plot_vowel_space(   vowel_data,   speakers = NULL,   vowel_colours = NULL,   label_size = 4,   means_only = TRUE,   ellipses = FALSE,   point_alpha = 0.1,   facet = TRUE )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_vowel_space.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot vowel space for speaker or speakers. — plot_vowel_space","text":"vowel_data data frame vowel tokens described . speakers list speaker identifiers speaker whose vowel space plotted. vowel_colours named list vowel = colour entries indicate colour plot vowel. label_size often convenient adjust size labels (pts). Default 4. means_only whether plot means data points. Default: TRUE. ellipses whether 95% confidence ellipses. works means_only FALSE. Default FALSE. point_alpha alpha value data points means_only FALSE. facet whether plot distinct speakers distinct facets. Default TRUE.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_vowel_space.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot vowel space for speaker or speakers. — plot_vowel_space","text":"ggplot object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/plot_vowel_space.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot vowel space for speaker or speakers. — plot_vowel_space","text":"","code":"# Plot mean vowel space across plot_vowel_space(   onze_vowels,   speakers = NULL,   vowel_colours = NULL,   label_size = 4,   means_only = TRUE,   ellipses = FALSE,   point_alpha = 0.1,   facet = FALSE  )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/procrustes_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate distribution of (index) loadings using the bootstrap and Procrustes rotation. — procrustes_loadings","title":"Generate distribution of (index) loadings using the bootstrap and Procrustes rotation. — procrustes_loadings","text":"Generate distribution loadings signed index loadings Principal Components. used order estimate confidence intervals loadings , signed index loadings used, also null distribution tests statistical significance. Plot results using plot_procrustes_loadings().","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/procrustes_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate distribution of (index) loadings using the bootstrap and Procrustes rotation. — procrustes_loadings","text":"","code":"procrustes_loadings(pca_data, max_pcs, index = TRUE, n = 500, scale = TRUE)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/procrustes_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate distribution of (index) loadings using the bootstrap and Procrustes rotation. — procrustes_loadings","text":"pca_data data fed prcomp function. max_pcs maximum number PCs rotate. index whether use signed index loadings rather loadings (default: TRUE) n number bootstrapped permuted samples. scale whether variables pca_data scaled PCA (default: TRUE)","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/procrustes_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate distribution of (index) loadings using the bootstrap and Procrustes rotation. — procrustes_loadings","text":"tibble, columns: source either \"Sampling\", \"Null\" \"Original\", identifying loadings comes . \"Original\" identifies loadings full dataset, \"Sampling\" identifies loadings bootstrapped samples, \"Null\" identifes loadings permuted versions data. id identifies iteration either permutation bootstrapping loading comes . variable indicates variable corresponding loading. column containing loading PC max_pcs.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/procrustes_loadings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate distribution of (index) loadings using the bootstrap and Procrustes rotation. — procrustes_loadings","text":"","code":"proc_loadings <- procrustes_loadings(     pca_data = onze_intercepts |> dplyr::select(-speaker),     max_pcs = 3,     index = TRUE,     n = 10, # set this to at least 100 in actual use.     scale = TRUE    )"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_intervals.html","id":null,"dir":"Reference","previous_headings":"","what":"Formant and amplitude for intervals of QuakeBox monologues — qb_intervals","title":"Formant and amplitude for intervals of QuakeBox monologues — qb_intervals","text":"QuakeBox monologues divided intervals fixed length within mean values calcualted formants, amplitude, articulation rate. Data 77 speakers provide (sample qb_vowels).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_intervals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Formant and amplitude for intervals of QuakeBox monologues — qb_intervals","text":"","code":"qb_intervals"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_intervals.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Formant and amplitude for intervals of QuakeBox monologues — qb_intervals","text":"data frame 53940 rows 10 variables: interval_length Length interval seconds. speaker Anonymised speaker code (char). interval Time seconds interval ends. articulation_rate Mean articulation rate within interval. amplitude Mean maximum amplitude within interval. DRESS_F1 Speaker intercept GAMM model DRESS F1. DRESS_F2 Speaker intercept GAMM model DRESS F2. FLEECE_F1 Speaker intercept GAMM model FLEECE F1. FLEECE_F2 Speaker intercept GAMM model FLEECE F2. GOOSE_F1 Speaker intercept GAMM model GOOSE F1. GOOSE_F2 Speaker intercept GAMM model GOOSE F2. KIT_F1 Speaker intercept GAMM model KIT F1. KIT_F2 Speaker intercept GAMM model KIT F2. LOT_F1 Speaker intercept GAMM model LOT F1. LOT_F2 Speaker intercept GAMM model LOT F2. NURSE_F1 Speaker intercept GAMM model NURSE F1. NURSE_F2 Speaker intercept GAMM model NURSE F2. START_F1 Speaker intercept GAMM model START F1. START_F2 Speaker intercept GAMM model START F2. STRUT_F1 Speaker intercept GAMM model STRUT F1. STRUT_F2 Speaker intercept GAMM model STRUT F2. THOUGHT_F1 Speaker intercept GAMM model THOUGHT F1. THOUGHT_F2 Speaker intercept GAMM model THOUGHT F2. TRAP_F1 Speaker intercept GAMM model TRAP F1. TRAP_F2 Speaker intercept GAMM model TRAP F2.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_intervals.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Formant and amplitude for intervals of QuakeBox monologues — qb_intervals","text":"https://osf.io/m8nkh/","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_intervals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Formant and amplitude for intervals of QuakeBox monologues — qb_intervals","text":"Two interval lengths given: 60 seconds 240 seconds. Formant data z-scored speaker vowel, amplitude articulation rate z-scored speaker. Original data generated Wilson Black et al. (2023).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_intervals.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Formant and amplitude for intervals of QuakeBox monologues — qb_intervals","text":"Wilson Black, Joshua, Jennifer Hay, Lynn Clark & James Brand (2023): overlooked effect amplitude within-speaker vowel variation. Linguistics Vanguard. Walter de Gruyter GmbH. 9(1). 173–189. doi:10.1515/lingvan-2022-0086","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_vowels.html","id":null,"dir":"Reference","previous_headings":"","what":"Formants from QuakeBox 1 — qb_vowels","title":"Formants from QuakeBox 1 — qb_vowels","text":"dataset containing formant values, amplitude, articulation rate, following segment data 10 New Zealand English monophthongs, along participant demographics.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_vowels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Formants from QuakeBox 1 — qb_vowels","text":"","code":"qb_vowels"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_vowels.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Formants from QuakeBox 1 — qb_vowels","text":"data frame 26331 rows 14 variables: speaker Anonymised speaker code (char). vowel Wells lexical sets 10 NZE monophthongs. Levels:  DRESS, FLEECE, GOOSE, KIT, LOT, NURSE, START, STRUT, THOUGHT, TRAP, FOOT (char). F1_50 First formant Hz, extracted vowel mid-point using LaBB-CAT interface Praat. F2_50 Second formant Hz, extracted vowel mid-point using LaBB-CAT interface Praat. participant_age_category Age category speaker. Values: 18-25, 26-35, 36-45, ..., 76-85 (char). participant_gender Gender participant. Values: M, F (char). participant_nz_ethnic New Zealand ethnic category participant. Values: NZ mixed ethnicity, NZ European, (char). word_freq Frequency word vowel token taken CELEX. word Anonymised word id (char). time Time seconds vowel segment starts. vowel_duration Length vowel seconds. articulation_rate Articulation rate utterance token taken. following_segment_category Category following segment. NB: liquids already removed. Levels: labial, velar, (factor). amplitude Maximum amplitude word vowel token taken, generated LaBB-CAT interface Praat.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_vowels.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Formants from QuakeBox 1 — qb_vowels","text":"https://osf.io/m8nkh/","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_vowels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Formants from QuakeBox 1 — qb_vowels","text":"Original data generated Wilson Black et al. (2023).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/qb_vowels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Formants from QuakeBox 1 — qb_vowels","text":"Wilson Black, Joshua, Jennifer Hay, Lynn Clark & James Brand (2023): overlooked effect amplitude within-speaker vowel variation. Linguistics Vanguard. Walter de Gruyter GmbH. 9(1). 173–189. doi:10.1515/lingvan-2022-0086","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/sim_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Similarity matrix from online perception test. — sim_matrix","title":"Similarity matrix from online perception test. — sim_matrix","text":"Mean similarity ratings 38 QuakeBox speakers online pairwise similarity task. Random noise added.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/sim_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Similarity matrix from online perception test. — sim_matrix","text":"","code":"sim_matrix"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/sim_matrix.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Similarity matrix from online perception test. — sim_matrix","text":"38x38 matrix","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/summary.correlation_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary function for correlation test object. Set alpha to change significance level. — summary.correlation_test","title":"Summary function for correlation test object. Set alpha to change significance level. — summary.correlation_test","text":"Set alpha change significance level n_cors change number pairwise correlations given.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/summary.correlation_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary function for correlation test object. Set alpha to change significance level. — summary.correlation_test","text":"","code":"# S3 method for class 'correlation_test' summary(object, alpha = 0.05, n_cors = 5, ...)"},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/summary.correlation_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary function for correlation test object. Set alpha to change significance level. — summary.correlation_test","text":"object object class correlation test, alpha significance level counting correlation significant. n_cors number pairwise correlations list. ... additional arguments affecting summary produced.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/reference/summary.correlation_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary function for correlation test object. Set alpha to change significance level. — summary.correlation_test","text":"glue object.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/news/index.html","id":"nzilbbvowels-041","dir":"Changelog","previous_headings":"","what":"nzilbb.vowels 0.4.1","title":"nzilbb.vowels 0.4.1","text":"CRAN release: 2025-05-06 Remove VignetteBuilder DRESCRIPTION. Now plot_procrustes_loadings() correctly sets y-axis label ‘Loading’ ‘Index loading’.","code":""},{"path":[]},{"path":"https://nzilbb.github.io/nzilbb_vowels/news/index.html","id":"breaking-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"nzilbb.vowels 0.4.0","text":"mds_test(), first argument changed similarity_matrix dissimilarity_matrix match behaviour expected users smacof::smacofSym()","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"nzilbb.vowels 0.4.0","text":"New pca_rotate_2d() takes output stats::prcomp() stats::princomp() rotates two specified PCs clockwise angle degrees. scores loadings rotated variance explained component updates. New pca_rotate_procrustes() allows Procrustes rotation output prcomp() princomp() match target configuration either scores loadings. Partial overlap variables enabled rotation_variables. scores loadings rotated variance explained component updates. New procrustes_loadings() generates data enable calculation confidence intervals loadings, confidence intervals null distributions index loadings, bootstrapping, permutation, Procrustes rotation. New plot_procrustes_loadings() provided plot output procrustes_loadings(). New articles package website https://nzilbb.github.io/nzilbb_vowels/ covering ‘model--PCA’ workflow used NZILBB use rotation PCA.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/news/index.html","id":"nzilbbvowels-031","dir":"Changelog","previous_headings":"","what":"nzilbb.vowels 0.3.1","title":"nzilbb.vowels 0.3.1","text":"CRAN release: 2024-11-29 Documentation fixes initial CRAN submission (nzilbb.vowels 0.3).","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/news/index.html","id":"nzilbbvowels-03","dir":"Changelog","previous_headings":"","what":"nzilbb.vowels 0.3","title":"nzilbb.vowels 0.3","text":"Initial submission CRAN mds_test() plot_mds_test() added determine number dimensions MDS. pc_flip() added reverse orientation selected PCs PCA analysis.","code":""},{"path":"https://nzilbb.github.io/nzilbb_vowels/news/index.html","id":"nzilbbvowels-021","dir":"Changelog","previous_headings":"","what":"nzilbb.vowels 0.2.1","title":"nzilbb.vowels 0.2.1","text":"functions required Wilson Black et al. (2022)","code":""}]
